// filepath: /workspaces/yaakaito/mcp-server/src/articles/generated-articles.ts
// このファイルは自動生成されています。手動で変更しないでください。
// 生成日時: 2025-05-17T20:18:11.866Z
import { Article } from './types';

/**
 * 全記事データ
 */
export const articles: Article[] = [
  {
    "id": "fixing-roo-code-browser-issues-in-dev-container",
    "title": "Roo Code の Browser が Dev Container で動かない",
    "content": "普段の開発は基本 Dev Container でやっているので、Roo Code もそのまま Dev Container 前提で触っていたが、動作確認なんかで Roo Code が使おうとするブラウザが動作しないのが気になったので直すことにした。\n2025/03/14追記: Cline では `PUPPETEER_EXECUTABLE_PATH` に相当するものが設定でき、コンテナに chromium をインストールしておけば動作する。最後に記載する。\n\n## 先に結論\n\nPuppeteer がホストやコンテナの CPU アーキテクチャに関係なく x86_64 を要求するので、 amd64 のライブラリを揃えて動くようにした。\n\n- https://github.com/puppeteer/puppeteer/issues/7740\n\nなんだかんだで Puppeteer を使う機会が一切無かったので全然知らなかった。puppeteer-chromium-resolver のドキュメントに必要なライブラリが書いてある:\n\n- https://github.com/cenfun/puppeteer-chromium-resolver/tree/master?tab=readme-ov-file#troubleshooting\n\nこれと日本語フォントとして `fonts-ipafont-gothic` を `amd64` でインストールする、これを `setup-browser-action.sh` としてまとめる:\n\n```sh\n#!/bin/zsh\n\n# マルチアーキテクチャを有効にする\nsudo dpkg --add-architecture amd64\n\n# リポジトリを修正（Debianの場合）\necho 'deb [arch=arm64] http://deb.debian.org/debian bookworm main contrib non-free non-free-firmware\ndeb [arch=arm64] http://deb.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\ndeb [arch=arm64] http://deb.debian.org/debian bookworm-updates main contrib non-free non-free-firmware\ndeb [arch=amd64] http://deb.debian.org/debian bookworm main contrib non-free non-free-firmware\ndeb [arch=amd64] http://deb.debian.org/debian-security bookworm-security main contrib non-free non-free-firmware\ndeb [arch=amd64] http://deb.debian.org/debian bookworm-updates main contrib non-free non-free-firmware' | sudo tee /etc/apt/sources.list\n\n# リポジトリを更新しライブラリをインストール\nsudo apt update\nsudo apt install -y \\\n        ca-certificates:amd64 \\\n        fonts-ipafont-gothic:amd64 \\\n        fonts-liberation:amd64 \\\n        libasound2:amd64 \\\n        libatk-bridge2.0-0:amd64 \\\n        libatk1.0-0:amd64 \\\n        libc6:amd64 \\\n        libcairo2:amd64 \\\n        libcups2:amd64 \\\n        libdbus-1-3:amd64 \\\n        libexpat1:amd64 \\\n        libfontconfig1:amd64 \\\n        libgbm1:amd64 \\\n        libgcc1:amd64 \\\n        libglib2.0-0:amd64 \\\n        libgtk-3-0:amd64 \\\n        libnspr4:amd64 \\\n        libnss3:amd64 \\\n        libpango-1.0-0:amd64 \\\n        libpangocairo-1.0-0:amd64 \\\n        libstdc++6:amd64 \\\n        libx11-6:amd64 \\\n        libx11-xcb1:amd64 \\\n        libxcb1:amd64 \\\n        libxcomposite1:amd64 \\\n        libxcursor1:amd64 \\\n        libxdamage1:amd64 \\\n        libxext6:amd64 \\\n        libxfixes3:amd64 \\\n        libxi6:amd64 \\\n        libxrandr2:amd64 \\\n        libxrender1:amd64 \\\n        libxss1:amd64 \\\n        libxtst6:amd64 \\\n        lsb-release:amd64 \\\n        wget:amd64 \\\n        xdg-utils:amd64\n```\n\nこれで動作自体はするが、 Roo Code が `--no-sandbox` で実行できるオプションを用意していなくて、それに対応する必要がある:\n\n- https://github.com/RooVetGit/Roo-Code/blob/main/src/services/browser/BrowserSession.ts#L56-L67\n\nSonnet によると `--cap-add=SYS_ADMIN` をつけてコンテナを起動すればいけるらしく、それらを組み込んだ `devcontainer.json` は次のようになり、これで動くようになった:\n\n```json\n{\n    \"image\": \"mcr.microsoft.com/devcontainers/base:1-bookworm\",\n    \"runArgs\": [\n        \"--cap-add=SYS_ADMIN\"\n    ],\n    \"postCreateCommand\": \".devcontainer/setup-browser-action.sh\",\n    \"features\": {\n        \"ghcr.io/devcontainers/features/node:1\": {},\n        \"ghcr.io/shyim/devcontainers-features/bun:0\": {},\n        \"ghcr.io/devcontainers/features/github-cli:1\": {}\n    }\n}\n```\n\n下にある元の設定と比べて `base:1` から `base:1-bookworm` になっているが、 `setup-browser-action.sh` と揃えるためで本質的には違いがない。\n\n\n## 動かない状態\n\nM2 MacBookAir で OrbStack を使っている。devcontainer.json はこれ:\n\n```json\n{\n    \"image\": \"mcr.microsoft.com/devcontainers/base:1\",\n    \"features\": {\n        \"ghcr.io/devcontainers/features/node:1\": {},\n        \"ghcr.io/shyim/devcontainers-features/bun:0\": {},\n        \"ghcr.io/devcontainers/features/github-cli:1\": {}\n    }\n}\n```\n\nこれで作ったコンテナ内に Roo Code をインストールして Browser を使うと次のようになる:\n\n```\nError executing browser action:\nFailed to launch the browser process!\nOrbStack ERROR: Dynamic loader not found: /lib64/ld-linux-x86-64.so.2\n\nThis usually means that you're running an x86 program on an arm64 OS without multi-arch libraries.\nTo fix this, you can:\n  1. Use an Intel (amd64) container to run this program; or\n  2. Install multi-arch libraries in this container.\n\nThis can also be caused by running a glibc executable in a musl distro (e.g. Alpine), or vice versa.\n\nFor more details and instructions, see https://go.orbstack.dev/multiarch\n\n\nTROUBLESHOOTING: https://pptr.dev/troubleshooting\n```\n\n特に指定していないのでコンテナは `aarch64`:\n\n```\n$ uname -m\naarch64\n```\n\n## その他の案\n\n### amd64 のコンテナにする\n\n`--platform=linux/amd64` としてコンテナ側のアーキテクチャを揃える案。これは過去に VSCode の拡張が動かないものが出てきたので避けたもの。よって採用したくないのと、そもそもビルドがうまくいかなくて早々に諦めた。\n\n### puppeteer が自前した Chromium を使うようにする\n\n詳しい説明は下の参考記事を見てもらったほうがよいので割愛するが、次のようなコンテナでいけるか試してみた:\n\n```json\n{\n    \"image\": \"mcr.microsoft.com/devcontainers/base:1\",\n    \"containerEnv\": {\n        \"PUPPETEER_SKIP_CHROMIUM_DOWNLOAD\": \"true\",\n        \"PUPPETEER_EXECUTABLE_PATH\": \"/usr/bin/chromium\"\n    },\n    \"postCreateCommand\": \"sudo apt update && sudo apt install -y chromium\",\n    \"features\": {\n        \"ghcr.io/devcontainers/features/node:1\": {},\n        \"ghcr.io/shyim/devcontainers-features/bun:0\": {},\n        \"ghcr.io/devcontainers/features/github-cli:1\": {}\n    }\n}\n```\n\nこれはうまくいかなかった。何が悪いのかちゃんと分かっていないが、 x86_64 で実行しようとする。環境変数を Roo Code が読んでくれない...？\n\n## 参考にした記事\n\n- https://zenn.dev/frog/articles/24a20e8a2811b5\n- https://zenn.dev/tom1111/articles/0dc7cde5c8e9bf\n- https://docs.orbstack.dev/machines/#multi-architecture\n\nめちゃくちゃ参考になったので、この記事がまた誰かの解決に役立つと良いと思い残そうと思った。\n\n## 2025/03/14 追記\n\nCline では `PUPPETEER_EXECUTABLE_PATH` に相当するものが設定でき、コンテナに chromium をインストールしておけば動作する。ので、この設定で動作するはず:\n\n```json\n{\n    \"image\": \"mcr.microsoft.com/devcontainers/base:1-bookworm\",\n    \"runArgs\": [\n        \"--cap-add=SYS_ADMIN\"\n    ],\n    \"postCreateCommand\": \"sudo apt update && sudo apt install -y chromium\",\n    \"customizations\": {\n        \"vscode\": {\n            \"settings\": {\n                \"cline.chromeExecutablePath\": \"/usr/bin/chromium\"\n            },\n        }\n    }\n}\n```",
    "createdAt": "2025-03-06T00:00:00.000Z",
    "updatedAt": "2025-03-06T00:00:00.000Z",
    "publishedAt": "2025-03-06T00:00:00.000Z",
    "tags": [],
    "path": "/blog/fixing-roo-code-browser-issues-in-dev-container"
  },
  {
    "id": "cf-vectorize-and-workes-ai",
    "title": "Cloudflare Vectorize と Workers AI で関連する記事を作ってみる",
    "content": "このブログは SSG したものを GitHub Pages にデプロイしているのですが、 Cloudflare Vectorize と Workers AI を使うと関連記事を表示することができそうだったので作ってみました。\n\nこのブログのリポジトリにある Worker として実装しています：\n\n- https://github.com/yaakaito/yaakaito/tree/main/related-articles-worker\n\nチュートリアルと被る部分も多々あるので、そちらも参考にしてください。\n\n- https://developers.cloudflare.com/vectorize/get-started/embeddings/\n\n## Workers AI による埋め込みベクトルの生成\n\n- https://developers.cloudflare.com/workers-ai/\n\nWorkers AI は Cloudflare Workers から各種 AI モデルを呼び出すことができるサービスです。モデルは結構色々あって、Text Embedding に使える `@cf/baai/bge-base-en-v1.5` というモデルがあり、今回はこれを使って記事の内容をベクトル化しています。\n\n- https://developers.cloudflare.com/workers-ai/models/\n\n`wrangler.jsonc` に設定を行い、次のようなコードでベクトルを生成できます：\n\n```jsonc\n{\n  \"ai\": {\n    \"binding\": \"AI\"\n  }\n}\n```\n\n```ts\nconst response = await env.AI.run(\"@cf/baai/bge-base-en-v1.5\", {\n    text: article.content,\n});\nconst embedding = response.data[0]; // number[]\n```\n\n`@cf/baai/bge-base-en-v1.5` は英語用のモデルで、現時点では英語のモデルしか利用できませんが、今回は Cloudflare Workers で完結させたかったため、精度には目をつぶることにしました。記事が少ないのでなんとも言えないですが、それっぽい結果にはなってる気がします。ここは好きなモデルを使えるので、 Workers AI ではなく、コードを書いて Open AI のモデルを使うとかでもよいです。\n\n## Vectorize でのベクトルデータの管理\n\n- https://developers.cloudflare.com/vectorize/\n\nCloudflare Workers から触れるベクトルデータベースで、手軽にベクトルの保存や検索を行うことができます。\n\n使用するために準備として wrangler からデータベースを作成します：\n\n```bash\nbun wrangler vectorize create related-articles-index --preset=\"@cf/baai/bge-base-en-v1.5\"\n```\n\nWorkers AI を使用する場合モデルに合わせてプリセットを指定することで、互換性のある設定が自動的に行われます。そうでない場合は、 `--dimensions` と `--metric` を指定して作成します。\n\n出力された設定情報を `wrangler.jsonc` に追加します：\n\n```jsonc\n{\n  \"vectorize\": [\n    {\n      \"binding\": \"VECTORIZE\",\n      \"index_name\": \"related-articles-index\"\n    }\n  ],\n}\n```\n\n### データの挿入\n\n検索対象にしたい記事をベクトル化してデータベースに登録します。 Worker AI で取得した `embedding` を、以下のように `upsert` で保存します：\n\n```ts\nawait env.VECTORIZE.upsert([{\n    id: article.id, // どこからでも作れるように、記事の URL に対応した形式にしている\n    values: embedding,\n    metadata: {\n        url: article.url,\n        title: article.title,\n        emoji: article.emoji,\n        content: article.content\n    },\n}]);\n```\n\nこれを適当な Web API としてまとめ、 GitHub Actions で SSG するときに全記事分リクエストを投げています。現状は記事数が少ないため、毎回全データを上書きする形で実装しています。\n\n## 関連記事の取得\n\n関連記事を取得する API は、次のような URL で記事の ID を受け取って類似度の高い記事を返します。\n\n```\nhttps://articles.yaakai.to/related_articles?id=note-1\n```\n\nこの API では、 ID に登録されているベクトルを取り出して、そのベクトルを利用して Vectorize の `query` メソッドで類似度の高い記事を検索しています：\n\n```ts\nconst sourceVectors = await env.VECTORIZE.getByIds([id]);\nconst matches = await env.VECTORIZE.query(sourceVectors[0].values, {\n    topK: 4,\n    returnValues: false,\n    returnMetadata: true,\n});\n```\n\n完全一致の記事（自分自身）を除外し、上位3件を関連記事として返しています：\n\n```ts\nconst relatedArticles = matches.matches\n    .filter(match => match.id !== id)\n    .slice(0, 3)\n    .map(match => ({\n        id: match.id,\n        url: match.metadata?.url as string,\n        title: match.metadata?.title as string,\n        emoji: match.metadata?.emoji as string,\n        content: match.metadata?.content as string,\n        similarity: match.score\n    }));\n```\n\nこのブログには、クライアントサイドからこの API にリクエストして、取得したデータを整形して表示しています。\n\n## ローカル開発環境\n\n注意点としてローカルでの開発時は、Workers AI と Vectorize を使用するために `--remote` オプションを付けて起動する必要があります：\n\n```bash\n$ wrangler dev --remote\n```",
    "createdAt": "2025-02-23T00:00:00.000Z",
    "updatedAt": "2025-02-23T00:00:00.000Z",
    "publishedAt": "2025-02-23T00:00:00.000Z",
    "tags": [],
    "path": "/blog/cf-vectorize-and-workes-ai"
  },
  {
    "id": "create-eye-catching-visuals-with-ai",
    "title": "ドット絵なアイキャッチを AI で作る機能を Roo Code で作ってみた雑記",
    "content": "ドットなアイキャッチを作りたいとずっと思ってはいたので、 Roo Code を本格的に触る題材として作った。\n最初の方の感想はその時にしか残せないので、さらに進む前にその過程のメモやら雑感やら考えていたことを書いたもの。\nこの記事のアイキャッチはデバッグに使っていたら愛着が湧いてしまったサイっぽいキャラクター。\n\n## 前提\n\n- AI Coding が初めてとかではなく、 GitHub Copilot の β に始まり Cursor Pro は 1 年くらい使っているし、 Cline 系も初めて触るとかではない\n- Tier 4 の 3.7 Sonnet\n- 素の Roo Code でどんなものかを試したかったので、 Code で書く以外は何もしていない、 rules やプロンプトをカスタマイズしていない\n- 一部は Cursor を使っている\n\n## 実装過程\n\nパッとこうすればいいがあったわけではないので、ざっくりとした枠組みから作りはじめた。\nベースとなるコードは前回作った関連記事のアプリで、新しく作るのも面倒なのでここに継ぎ足す形に。\n\n```\nWorkers AI を利用して、アイキャッチ画像を生成するようにします。まずは、どんな画像が作れるかを検証するための簡単アプリを  related-aritcles-worker に機能追加する形で作成してください。\n以下の仕様を実現してください:\n\n- `/create_eyecatch` エンドポイントを作成し、受け取った記事の本文から Workers AI を用いて画像を生成します\n    - モデルには `@cf/black-forest-labs/flux-1-schnell` を使用します\n    - モデルのドキュメントはこれです: https://developers.cloudflare.com/workers-ai/models/flux-1-schnell/\n- index.html に記事の本文を送信できるフォームを新たに作成し、画像が生成できたら表示してください\n```\n\nとりあえず記事をそのまま Workers AI の画像生成に投げ込んでみた、それっぽいアプリは出来るが、生成がうまくいくはずもなく文字数オーバー。\n\nここであった主なやりとり:\n- dev-server が起動できない\n    - Dev Container で動かしているので `wranlger` の起動に `--ip` が必要で、 `package.json` の `script` には書いているんだけど頑なに無視する、 rules で制御できるといいんだろうか？\n- ブラウザが起動できない\n    - ちゃんとわかってないが Dev Container 使っているのでホストとのアーキテクチャの違いでうまくいっていないみたいな話、多分私が悪い\n\n\n画像生成をキーワードで行うようにする:\n\n```\n`/create_eyecatch` での画像生成フローを改善します、以下のフローを実現してください。\n\n- 画像生成より前に、 Text Generation なモデルを通して、記事からキーワードを抽出します\n- モデルは @cf/meta/llama-3.3-70b-instruct-fp8-fast を使ってみてください: https://developers.cloudflare.com/workers-ai/models/llama-3.3-70b-instruct-fp8-fast/\n- 抽出したキーワードと以下の固定のプロンプトを組み合わせて 2000 文字以内のプロンプトを @cf/meta/llama-3.3-70b-instruct-fp8-fast に作成させます\n    - 「ブログのアイキャッチ、背景は単色、人間を含まない、アニメ調」\n- 最終的なプロンプトを使って画像を生成します\n```\n\n実装自体は意図通りにやってくれる、ただし意図した画像はでない。プロンプトがゴミなので当たり前すぎる話ではある。ここでなんとなく Open AI の DALL-E を使ってみたくなったので、切り替えてみる。\n\n```\n現在画像生成を Cloudflare の Workers AI で行っていますが、これがうまくいっていないので OpenAI のものに置き換えます。\n\n- プロンプト作成部分は現状を維持します\n- 画像生成を DALL·E 3 を使った実装に置き換えてください\n- APIKEY は後ほどこちらで設定するので env に OPENAI_API_KEY が設定されている前提で進めてください\n```\n\nサイズ固定が出来るようになって(Workers AI でも出来るものはある)、出力が安定した気がするがほしい感じの画像はまあでない。\n\n## ロジックを見直す\n\n記事内のキーワードからそれっぽい画像を作るのはなかなか厳しいことがわかったので、別の方法を考えた。\nオライリーっぽい感じで、キーワードと動物を関連付けるのはどうかなと思いつつ適当に Sonnet と話していたら Sonnet もそう言っていたので、そうすることにした。\nカテゴリごとに動物と背景色をざっくりと決めて、それをベースに作ってもらえるようにお願いするプロンプトを Sonnet と考える。\n\n最終的にこんな感じに、オライリーのぱｋリスペクト、メンダコ(dumbo-octopus)は適当にメモにかわいいとか書いてたら Sonnet が入れた:\n\n```\n`/create_eyecatch` の既存のキーワード抽出および画像生成コードを活用・改良し、技術キーワードに対応するドット絵動物キャラクターをベースとしたブログ記事用アイキャッチ画像を生成するシステムを完成さてください。\n\n## 実装内容\n1. キーワード-動物マッピングシステムの拡張\n以下のマッピングテーブルを既存コードに組み込む：\n\nconst techAnimalMap = {\n  \"cloudflare\": { animal: \"alpaca\", backgroundColor: \"#F38020\" },\n  \"ai\": { animal: \"owl\", backgroundColor: \"#8A2BE2\" },\n  \"javascript\": { animal: \"rhino\", backgroundColor: \"#F7DF1E\" },\n  \"typescript\": { animal: \"guanaco\", backgroundColor: \"#3178C6\" },\n  \"html\": { animal: \"koala\", backgroundColor: \"#E34F26\" },\n  \"css\": { animal: \"fish\", backgroundColor: \"#1572B6\" },\n  \"database\": { animal: \"dumbo-octopus\", backgroundColor: \"#336791\" }\n};\n\n2. キーワード抽出ロジックの強化\n\n既存のキーワード抽出コードを利用し、記事内容から上記に定義されたキーワードの出現頻度を分析\n最も関連性の高いキーワードを特定するロジックを追加\n複数の関連キーワードがある場合の優先順位付けメカニズムを実装\n```\n\nこの辺から画像生成 AI に投げるプロンプトを私が読まなくなったので、全部英語に変えてもらった。プロンプトに更に注文をつけていく:\n\n```\n画像生成プロンプトを次のように改善して\n\n- 8bitゲーム風のレトロな作風に\n- キャラクター以外のアイコンやテキストを極力含まない\n```\n```\nプロンプトを更に改善します\n\n- キャラクターのドット絵には黒い縁をつける\n```\n\n他にも色々投げた気がしますが、かなりいい感じの画像が返ってくるようになった。最終的なプロンプトのコードはこんな感じ:\n\n```ts\nconst variations = [\n    \"cute and playful\",\n    \"simple and minimalist\",\n    \"detailed and expressive\",\n    \"cheerful and colorful\",\n    \"cool and stylish\"\n];\nconst imageResponse = await openai.images.generate({\n    model: \"dall-e-3\",\n    prompt: `Create an 8-bit retro game style pixel art of a ${animal} character representing the concept of ${selectedTechKeyword} and ${keywordsString}.\n    The character should be centered on a solid ${backgroundColor} background.\n    Style: Classic 8-bit NES/Famicom era pixel art, extremely limited color palette (4-8 colors maximum), ${variations[index]}.\n    IMPORTANT: The ${animal} character MUST have a black outline/border around it - this is essential for the retro game look.\n    The black outline should be exactly 1 pixel thick and should completely surround the character.\n    The ${animal} character should be the ONLY element in the image - no icons, symbols, text, UI elements, or any other objects.\n    Make it look like a character sprite from an 80s video game with sharp pixels, no anti-aliasing.\n    The final result should be clean, minimalist, and instantly recognizable as an 8-bit game character with a distinct black outline.\n    The final image should be exactly 64x64 pixels in size.`,\n    n: 1, // DALL-E 3では1枚ずつ生成\n    size: \"1024x1024\", // DALL·E 3で利用可能なサイズ\n    quality: \"standard\",\n    response_format: \"b64_json\",\n});\n```\n\nネガティブっぽいプロンプトは書いても聞いてくれないどころか、書くとほぼ含めてくるようになるのでやめた。 `backgroundColor` はだいたい無視される。これを 5 リクエスト同時に投げて 5 枚づつ作るようにしている。\n\nちなみに適当に検証したタイミングで画像生成はやめて、開発中は適当に作ったものに固定すればよかったが、頭が回らずに無駄に $10 くらいクレジット溶かした(戒め1)。\nあとこんな感じに、ちょっとうまくいったな！と思ったタイミングで絶対に git commit した方がいい(戒め2)。\n\n## ドット絵にする、地獄の始まり\n\nこの手の画像の生成をやったことがある人は知っていると思うが、生成 AI が作るドット絵はドット絵ではない。わからないと何を言っているんだという感じだが、この記事のサムネの元になった画像を見てみるとわかりやすいと思う:\n\n<img src=\"/images/create-eye-catching-visuals-with-ai-01.png\" alt=\"original\" />\n\nパット見拡大されたドット絵に見えるが、斜めに切れているドットがあったり、1ドットの中に複数の色が存在したりしている。目とか耳を見るとドット絵としてはまぁない状態になっていることがわかりやすいはず。\nこれを補正して、うまくドット絵にするのが目標。ネタバレするとすべて機械化することは諦めて、最終的には人間が細かい修正をする形に落ち着いた。\n\nさて、これをどう修正していくかというと、まずは範囲選択 → 選択した範囲を 128x128 px のドット絵と見立てる → それぞれのドットを一番多い色で塗りつぶす、というのを考えた。\n\n```\n自動生成したアイキャッチ用画像に簡単な加工が出来るようにします。これは、ブログ全体での画像のテイストをなるべく揃えるために必要な作業です。\n次のような加工をしたいと考えています:\n\n- 背景色を透過処理\n- 生成された画像から、アイコン部分だけをユーザーが範囲選択して切り抜き\n- 切り抜いた画像をニアレストネイバー法を用いて 128x128 に縮小\n- 4倍である 512x512 に拡大、1ドット辺り 4x4 を利用する状態にする\n- この画像を 1200x630 のキャンバスの真ん中に配置する\n- キャンバスの背景を指定された 1 色で塗りつぶす\n\nこれを次のようなフローで実現したいと考えています:\n\n- `/create_eyecatch` で候補となる画像を複数枚生成\n- クライアントでユーザーが範囲指定して切り抜きを行う\n- 縮小、拡大、補正を行ったキャラクターをユーザーが確認できる形で出力\n- ユーザーが決定したら、1200x630のキャンバスに配置し、アイキャッチとして出力する\n\n各ステップでキャンセルして先頭に戻せるようにしてください\n```\n\n結論からいうとこれは全くうまくいかなかった。望む状態になるよう何度か修正を加えたが、範囲選択ができ、切り抜きを行って 128x128 に縮小する... というところまではいくが、その画像が綺麗ではない。\nそもそも生成された画像のドットのサイズがまちまちなので、固定値で出来るようなものでもなく、という感じ。\n一方で全体の UI とフローというか、要素の配置があまりにも適当すぎる(これは指示を一切していないのも悪いが)ことを除けば、操作自体はそれっぽくできる、すごい。\nここで作ったドット絵化のロジックはすべて消えているが、 UI の枠組みはここで作ったものを最後まで使うことになった。\n\n次にグリッドに区切ってそれぞれのドットを一番多い色で塗りつぶす、というのを考えた。イメージとしてはこんなの:\n\n<img src=\"/images/create-eye-catching-visuals-with-ai-02.png\" alt=\"original\" />\n\n```\nindex.html へ画像の加工機能を実装します、これは `/create_eyecatch` で生成された曖昧なドット絵(Pixel Art)をきれいなドット絵に加工し、最終的に 1200 x 630 のサイズにします。\n\n## 前提\n- `/create_eyecatch` で生成される画像は 1024x1024 px です\n- そこに、拡大された 64x64 px 程度のドット絵が書かれています\n- ただし、ドット絵としては歪みもある画像になっています\n     - 例えば、拡大された一つの Dot を複数の色が構成しています\n     - ドット絵には存在しないはずの、円形の Dot が存在します\n\n## 実装する機能のフロー\nドット絵として不正な Dot を補正して、ドット絵を完成させます。\n\n1. まず返却された複数の画像から一つをユーザーが選択します\n2. 選択された画像にグリッドを表示します、このグリッドは 8 x 8 pxを 1 dot として扱います、言い換えると全体を 128 x 128 px のキャンバスだと見立てるということです\n3. グリッドの大きさはスライダーでユーザーが調整できるようにします\n4. ユーザーがグリッドのサイズを決定したら、画像を変更する処理に入ります\n5. 処理した画像を出力します、1200 x 630 のキャンバスにはまだ入れる必要はありません\n\n## 画像処理の詳細\nユーザーが決めたグリッドにそって、Dot の塗りつぶしを行います\n\n- グリッドで区切られた Dot の中で、最も多く使われている色を計算します\n- その色で、その Dot をすべて塗りつぶします\n- 使った色を記録しておきます\n- すべての Dot を塗りつぶしたあと、使った色の数が 16 種類以上ある場合、色を少なくする処理を行います\n      - 近い色をまとめ、16 種類にします\n      - まとめられた色を、まとめた色で置き換えます\n      - 縁の装飾のため真っ黒(#000) は必ず残します\n      - 最終的な色の分布が、同じ系統の色に偏らないようにしてください\n\nこの処理を行うことで、例えばグリッドのサイズが 8x8 px であれば、1024x1024 の画像が 128x128px のドット絵となることを期待します。\n```\n\n```\n色の絞り込みのルールを変更します。\n\n- 基本的には、使われている回数が多い順に採用し、16 色に収めます\n- 人間が識別できない濃淡の差がある色がある場合は、それをまとめます\n- この中に、四隅のそれぞれ 4 Dot の色は含まないでください\n- 四隅の 4Dot と極めて近い色を持つ Dot はすべて同じ色にします\n```\n\n```\n'related-articles-worker/public/index.html' (see below for file content) に実装されている画像編集機能をさらにパワーアップします。\n既存のドットの補正、色の補正の処理が終わったあと、ユーザーがさらに修正を行い、最終的に 1200 x 630 の画像として出力します。\n以下の機能を追加してください:\n\n- 補正が終わった画像に対して、使われている色を利用して 1 Dot 単位の変更が出来る機能の追加\n- 補正が終わった画像に対して、使われている色を利用して連なっている同色をすべて塗りつぶす機能の追加\n- その後、画像の4隅の色と同じ色で塗りつぶした 1200x630 のキャンバスを用意し、任意の位置に加工済みの画像を配置できるようにする\n- 背景色を変更できるようにする\n\n## ユーザーによる画像の補正\n\n- 利用している 16 色のパレットから、任意の色を選んで、\n     - クリックした Dot をその色に置き換える事ができる\n     - 連なっている同色を塗りつぶすことが出来る\n          - 塗りつぶしツールを実装する\n```\n\n1 回では不足していたので、細かい修正依頼とかはしつつも大まかに 3 つのプロンプトで機能全体ができた。\nこれはこの時点でかなりいいものが出てきていて、なるべく脳をプロンプトに dump したかいがあったなと感じた。\n\n<img src=\"/images/create-eye-catching-visuals-with-ai-03.png\" alt=\"original\" />\n<img src=\"/images/create-eye-catching-visuals-with-ai-04.png\" alt=\"original\" />\n\nこれにグリッドのオフセットを付け加えたり、 Undo が出来るようにしたり、というのを対話で雑に加えていった。 Undo を作っている途中で一度コンテキストが足りなくなったので、新しいプロンプトで次の指示をしたらわりと察してやってくれた:\n\n```\n@/related-articles-worker/public/index.html にはドット絵を編集する機能がありますが、 undo 機能を実装する途中で止まってしまっています。\nundo 機能を完成させてください。\n\n- 10 回まで undo が出来る\n-  ctrl + z をショートカットに設定する\n```\n\nこのあたりから結構バグ修正というか、動作して気に入らなかったり、動いてなかったりというのを修正することが増えた。\nあと、この機能の実装を全部 index.html 1 ファイルに詰め込んでいたので、 1 回で使うコンテキストの量があからさまに多くなってきた。\n\nバグ修正の基本的なやりかたとしては、 UI が関わるものは気に入らない部分を SS して、文句と一緒に投げていた。これで基本的には解決してくれる。\n\n<img src=\"/images/create-eye-catching-visuals-with-ai-05.png\" alt=\"original\" />\n<img src=\"/images/create-eye-catching-visuals-with-ai-06.png\" alt=\"original\" />\n\n唯一「グリッドと画像がずれる」という問題をどうしても Roo Code では解決できなくて、Cursor と解決した。\n\n<img src=\"/images/create-eye-catching-visuals-with-ai-07.png\" alt=\"original\" />\n\nこの辺はいつもどおり Dev Tool からおかしい CSS やら調べたりということしていて、だいたいわかったところで原因がありそうな行を Cursor に投げて直してもらった。\nCursor で直したものは、動作の不具合としてはこれともう一つ。そっちは多分 Cursor でも出来たが、だいたい検討がついていたので Cursor に投げたほうが早いよなとなった。\n\n実装をさらに進めていって、最終的な出力を調整出来る段階まで来たので、細かい位置やドットの大きさを指定できるようにしたい:\n\n```\n@/related-articles-worker/public/index.html のドット絵編集機能を改善します。最終的にアイキャッチとして 1200 x 630 px のサイズで画像を出力します。\n以下の機能を実装します:\n\n- 画像の倍率を調整する機能\n- 画像の位置を中心からのオフセットで調整する機能\n- 選択した色をすべて背景色として扱う機能\n\n## 倍率を調整する機能\n\nこの編集機能はグリッドの大きさを設定することができます。\n例えば 16px のグリッドを設定した場合、ドット絵として見た場合は 16x16 px が 1 ドットとして扱われるため、16倍に拡大された画像ということになります。\nこの倍率を最終的な出力では自由に調整できるようにして、画像の大きさを調整します。\n\n次のように実現します:\n- 1x 2x 4x 8x 16x のような刻みで倍率を選択出来るようにする\n     - この倍率は、元画像からの倍率ではなく、ドット絵を 1 ドット = 1x1px に正規化した場合の倍率です\n     - 例えば、16px のグリッドで作成された場合も 8x を選んだのであれば 1 ドットが 8x8px のグリッドで構成されるドット絵になります\n\n\n## 選択した色をすべて背景色として扱う\n\n最終的な出力の背景を単色としたいので、同一の色で塗りつぶす必要があります\n加工中の画像の背景色はランダムなため、パレットから背景色として扱う色を複数個選べる必要があります\n選んだ色と、1200x630 を確保して生まれた余剰部分の色をすべて同じにして、単色での背景を実現します\n```\n\nこれだとドット絵をそのまま引き伸ばして悲しい感じの画像になっていたので、間違っているよといったら理解してくれた:\n\n```\n@/related-articles-worker/public/index.html でのドット絵編集の最終段階である 1200 x 630 でのアイキャッチ出力部分を改善します。\n倍率を変更する際に、元々のグリッドと倍率が異なると色の境界がぼやけるようになっています。これは間違った実装です。\n画像の引き伸ばしではなく、ドットのサイズのみを変更します。\n```\n\n### アップロードと配信部分を作る\n\n生成するだけで配信をしていないので、作った画像を記事に関連付けて取れるようにする機能を足す。\n\n```\n@/related-articles-worker/src/index.ts にアイキャッチ画像を配信する機能を追加します。アイキャッチ画像は @/related-articles-worker/public/index.html で作成できるようになっています。\n次のフローを実装してください:\n\n1. `/registier` で登録されたとき、これまでの処理に追加して、id と本文の内容をセットで KV へ保存します\n2. このとき、まだアイキャッチは作られていません\n3. index.html で画像生成を開いたとき、まだアイキャッチのない記事の一覧を表示します\n4. 記事を選ぶと、対象の id を `/create_eyecatch` に送り、既存のフローでアイキャッチを作成します\n5. 作成したアイキャッチをアップロードするエンドポイントを新たに実装し、そこへアイキャッチを送信します\n      - また、id を指定して画像をアップロードする方法も同時に用意してください\n6. `/eyecatch?id=${id}` で、登録したアイキャッチが画像として返ってくるようにします\n\nデータストアが必要であれば、 Workers の KV を利用してください。\n```\n\n特に間違いもなく一瞬で終わる、 index.html がでかすぎて一度途切れたが、「以下のプロンプトではじめた実装の続きをしてください」 という指示で同じプロンプトを貼り付けたらうまいことしてくれた。\n直接アップロードする機能とかも適当に開発させて終わり。書くことが特にない、こういうのが得意なのはそれはそうという感じ。\n\n## 雑感\n\n### まあ安くはない\n\n差額で見た感じ、今回の機能を作るのに $25 くらいかかっていた。ここにすべてのプロンプトを載せているわけではない。\n土日の可処分時間でやったもので、全部自分で書いたらこうはならなかったなと思うと時間を買えた感覚はあるのだが、今後の趣味の開発がこのペースで進むとして単純に 4 週で月 $100 + α。\nここに Cursor Pro と Claude Pro 、API と叩いているツールもろもろの利用料が乗ってなんやかんやで AI に掛かる費用が月 $200 くらいになるのかと思うとなかなか。\n\nただ、今回ちゃんとやるために Tier 4 に引き上げたが、 Tier 4 未満の Roo Code は考えられないのでやるならまず Tier 4 にした方がいい。低い Tier で使ったこともあり、そのときは微妙という感想だった。\n\n### 自分でも曖昧な部分の開発が重い\n\nこれはわかっていた話というか、別に普段の開発でも変わらないところ。今回でいうとドット絵の編集。\n完全に人間がやる場合と比べて、とりあえずプロンプトを書けば何かは出てくるので、それを触ってみて「やっぱだめだよな」が気軽にできるのはよかったと思う。\nので、別に AI も得意ではないけど、人間がやる理由にはならないとは思った。困ったらそれこそ Chat で相談とかでもよい。\nただ、これをやるのに、後述のセーブポイントはまじでたくさん作ったほうがいいと思った。\n\n### コンテキストでかすぎ問題\n\nこれは index.html にすべての実装を乗せていったのが完全に悪いのだけど、最後の方は 2500 行程度になって 3 回往復したらコンテキストが足りなくなる、みたいになっていた。\n後で実際のやりとりを除いてみると、ほぼ毎回 index.html をめちゃくちゃ送っている、でかい。ファイル指定しているからそりゃそう。\n\n今回これを回避するのに、前のプロンプト貼り付けて「多分続きまでやってるからなんとかして」みたいな指示をしていた。\nこの進め方自体の是非はともかく、 Roo Code は結構察して進めてくれるので、素直にすごいなと思った。\n\nコンテキストが足りるようにコードを適切に分割しろという話ではあって、コードのファイルを分ける基準が今後はわりとここに関係してきそうだなと思った。\n今回 rules なんかは全く使っていなくてこれなので、改善できるんだろうなぁとは思いつつも、これ以上にコンテキストに何かを入れることが出来るのか...? という気持ちが強い。\n\n### セーブポイントをたくさん作れ\n\ngit commit をたくさんしろ、というのとほぼイコール。\n少しでも期待した動作になったり、進捗が出たと思ったらすぐに commit する癖をつけるのがいいと思った。\nここまでをなしにして実装をやり直したい、と思うことが結構あって、その時点で commit がなくて Roo Code の戻すのをお願いしたりしていた。虚無。\n\n### プロンプトは適当でもわりとなんとかなる\n\nここの機能を実装したいときの指示書、みたいなものは結構適当でもいいなという感覚がある。最悪対話で修正すればよくて、これは Cursor でもそう感じていた。\nある程度フォーマット化されているのがいいとは思いつつも、曖昧なことやノイズが入っていなければなんとかなる、という印象。\nそれよりもコードベース全体を理解させることの方がはるかに重要だろうな、という感じ、そりゃそう。今回はほぼすべてが index.html だったので、逆にそこは解決されていた感があった。\n\n### デザイン適当すぎ問題\n\nこれは何も指示していないのがだいたい悪いとは思うんだけど、誰が使えるんだその UI みたいなのが平気で出てくる、基本縦に長過ぎる。",
    "createdAt": "2025-03-02T00:00:00.000Z",
    "updatedAt": "2025-03-02T00:00:00.000Z",
    "publishedAt": "2025-03-02T00:00:00.000Z",
    "tags": [],
    "path": "/blog/create-eye-catching-visuals-with-ai"
  },
  {
    "id": "popover-dialog",
    "title": "Popover API と Dialog に関する備忘録",
    "content": "2024 年の Baseline に追加された機能として Popover API があり、またそれに関連するものとして Dialog がすでに実装されている。\nこの 2 つは目的は違うが技術的には似たものになっているので、それぞれの特徴などをまとめる。\n\n動作サンプル: https://yaakaito.github.io/code-sandbox/popover-and-dialog/\n\n## 前提知識\n\n### Top Layer\n\n- [Top layer (最上位レイヤー) - MDN Web Docs 用語集: ウェブ関連用語の定義 | MDN](https://developer.mozilla.org/ja/docs/Glossary/Top_layer)\n\n従来のz-indexとは異なる、ブラウザネイティブの最前面レイヤー。PopoverとDialogのモーダルモードは、このTop layerを利用して要素を描画する。入れ子も可能だが、Light Dismiss（要素外クリックでの閉じる）の挙動には注意が必要となる。\n\n\n## 利用用途による違い\n\n- Popover\n    - カレンダーのようなフォームでの特殊な入力 UI\n    - 通知、トースト\n    - チュートリアル UI\n- モーダル Dialog\n    - 利用規約への同意のようなそれ以外を操作できないような UI\n    - 削除のような重要な確認操作\n- 非モーダル Dialog\n    - Cookie の利用許可のような、ユーザーに同意を求めるが、コンテンツは操作できる UI\n    - プライベート URL で共有を行うようなコンテンツでの、共有に関する警告の UI\n\n## Popover\n\n[ポップオーバー API - Web API | MDN](https://developer.mozilla.org/ja/docs/Web/API/Popover_API)\n\nPopover は属性で、任意の要素を Top layer へ配置することができる。ダイアログやモーダルではないので、アクセシビリティといった視点で意味は持たず、基本的には背景の要素に操作が貫通する。\n\n```html\n<button popovertarget=\"mypopover\">toggle popover</button>\n<div id=\"mypopover\" popover=\"auto|manual|hint\">Popover content</div>\n```\n\npopover 属性には現状 3 つの値を設定することができ、これによって Light Dismiss や表示方法をコントロールする。\n\n- `auto`: デフォルト値で、Light Dismiss が有効になる\n- `manual`: Light Dismiss が無効になり、閉じるための動作を実装する必要がある\n- `hint`: 「hint」は Chrome 133 から導入された（される予定の）機能で、この値が設定されている Popover は同時に1つしか表示されない\n\nJS からもコントロール可能だが、必ず属性に `popover` が付与されている必要がある。\n\n```jsx\npopover.showPopover()\npopover.hidePopover()\n```\n\n## Dialog\n\n[&lt;dialog&gt;: ダイアログ要素 - HTML: ハイパーテキストマークアップ言語 | MDN](https://developer.mozilla.org/ja/docs/Web/HTML/Element/dialog)\n\nDialog はユーザーに操作を求めるための役割（`role=dialog`）を持つ。モーダル/非モーダルの2つのモードがあり、特にモーダルモードではTop layerへの表示と背景操作のロックを行う。JS での制御が想定されていて、`showModal()` を利用することでモーダルダイアログが、`show()` を利用することで非モーダルダイアログが表示される。\n\n```html\n<dialog id=\"dialog\">\n    <h1>Dialog</h1>\n    <p>This is a dialog.</p>\n    <button>Close</button>\n</dialog>\n<script>\n    const dialog = document.getElementById('dialog');\n    dialog.showModal();\n</script>\n```\n\nモーダルの場合、次の機能がブラウザネイティブで提供される。これによって、これまでの実装よりもアクセシビリティや UX の向上が期待できる。\n\n- inert による背景 UI のロック\n    - [inert - HTML: ハイパーテキストマークアップ言語 | MDN](https://developer.mozilla.org/ja/docs/Web/HTML/Global_attributes/inert)\n    - `.showModal()` で表示された Dialog は、Top Layer でない要素が inert となる\n- :backdrop による背景の表示\n    - [::backdrop - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/::backdrop)\n    - Top layer と背景コンテンツの間に表示される領域で、モーダルダイアログではデフォルトで半透明の背景が表示されており、ユーザーの操作を受け付けないことを表現している\n- ESC での閉じるのサポート\n    - Light Dismiss ではない\n- フォーカスの管理\n    - モーダルダイアログが表示された際に、その中の要素にフォーカスが移動する\n    - ダイアログが閉じられた際に、直前のフォーカス位置に戻る\n\n\n## Anchor Positioning\n\n[CSS アンカー位置指定の使用 - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_anchor_positioning/Using)\n\n特定要素を基準とした配置をサポート。Top layer要素でも有効で、Popoverと組み合わせて使用できる。\n\n```html\n<style>\n   #anchorPopoverTrigger {\n        anchor-name: --anchor-target;\n   }\n   #anchorPopover  {\n        position-anchor: --anchor-target;\n        position-area: bottom span-right;\n        position-try-fallbacks: flip-inline, flip-inline flip-block;\n        margin: 0;\n        width: 300px;\n   }\n</style>\n<button id=\"anchorPopoverTrigger\" popovertarget=\"anchorPopoverLeft\">toggle anchor popover</button>\n<div id=\"anchorPopover\" popover>\n    Anchor Popover Left\n</div>\n\n```\n\nposition-area による配置指定が基本となりそうだが、top や left などを使用した直接的な位置指定も可能。\n\n- [https://developer.mozilla.org/ja/docs/Web/CSS/CSS_anchor_positioning/Using#position-area_の設定](https://developer.mozilla.org/ja/docs/Web/CSS/CSS_anchor_positioning/Using#position-area_%E3%81%AE%E8%A8%AD%E5%AE%9A)\n\nfallback を設定することができ、画面に収まらない場合の挙動を調整することが出来る。\n\n- https://developer.mozilla.org/en-US/docs/Web/CSS/position-try-fallbacks\n\n### Close Watcher\n\n[CloseWatcher - Web APIs | MDN](https://developer.mozilla.org/en-US/docs/Web/API/CloseWatcher)\n\nユーザーが閉じようとした動作を検知できる API で、具体的には ESC や戻るを押したタイミングが検知できる。`popover=manual` や非モーダルダイアログには ESC での閉じる機能がないので、対応する必要が出てきたときに有効。\n\n```jsx\nlet closeWatcher = null\npopoverTrigger.addEventListener('click', () => {\n    if (closeWatcher) {\n        closeWatcher.destroy()\n    }\n    closeWatcher = new CloseWatcher()\n    closeWatcher.onclose = () => {\n        popover.hidePopover()\n    }\n    popover.showPopover()\n})\n```\n\n## Refs\n\n- [#Tags | blog.jxck.io](https://blog.jxck.io/tags/#popover)\n- [CSS Anchor Positioning 仕様の紹介](https://zenn.dev/d_kawaguchi/articles/css-anchor-positioning-294aa71a7f77fc)\n- [UI を閉じる動作を処理する CloseWatcher API](https://azukiazusa.dev/blog/close-watcher-api/)",
    "createdAt": "2025-01-23T00:00:00.000Z",
    "updatedAt": "2025-01-23T00:00:00.000Z",
    "publishedAt": "2025-01-23T00:00:00.000Z",
    "tags": [],
    "path": "/blog/popover-dialog"
  },
  {
    "id": "cf-workers-static-assets-and-frameworks",
    "title": "Cloudflare Workers の Static Assets と Frameworks を試す",
    "content": "これを書いている時点ではβ版となっていますが、 Cloudflare Workers に Static Assets と Frameworks という機能が追加されていて、これまで Pages 側の機能だった静的ファイルの配信が Workers に統合されつつあるようです。これを利用すると Workers 単体で SSG なコンテンツを配信したり、 Next.js や Astro のサーバーサイド機能をうまく使うことが出来るようなので、これはそのサンプルを触ってみたログです。\n\n- [Static Assets · Cloudflare Workers docs](https://developers.cloudflare.com/workers/static-assets/)\n- [Frameworks · Cloudflare Workers docs](https://developers.cloudflare.com/workers/frameworks/)\n\nチュートリアルをなぞって少し手を加えた程度のものですが、コードは以下にあります。\n\n- https://github.com/yaakaito/workers-static-assets-example\n\n## 基本的な機能\n\n特にフレームワークを利用しないプレーンなアプリは [Deploy a full-stack application](https://developers.cloudflare.com/workers/static-assets/get-started/#deploy-a-full-stack-application) に従って以下のコマンドでこれを試すことができます。デフォルトが Vite なので、個人的にはもっとシンプルな構成であると嬉しかったです。\n\n```shell\n$ npm create cloudflare@latest -- my-dynamic-site --experimental\n```\n\n生成されたものをみると、Wrangler の設定ファイルである `wrangler.json` もしくは `wrangler.toml` に `assets` フィールドが追加されていて、これで設定を行うようです。\n\n- [Configuration and Bindings · Cloudflare Workers docs](https://developers.cloudflare.com/workers/static-assets/binding/)\n\nJSON の場合は次のようにディレクトリを指定すると、そのディレクトリ以下のファイルが `wrangler deploy` でアップロードされます。\n\n```json\n{\n  \"main\": \"src/index.ts\",\n  \"assets\": {\n    \"directory\": \"./public/\"\n  }\n}\n```\n\nここに該当するファイルがあれば Workers の `main` よりも先にそれが返され、そうでなければ `main` に指定したスクリプトに到達するようです。\n\n## Next.js + PPR\n\n- [Next.js · Cloudflare Workers docs](https://developers.cloudflare.com/workers/frameworks/framework-guides/nextjs/)\n\n```shell\n$ npm create cloudflare@latest my-next-app -- --framework=next --experimental\n```\n\n`@opennextjs/cloudflare` を利用して、 Workers で動作する形にビルドしているようです。\n\n- [Index - OpenNext](https://opennext.js.org/cloudflare)\n- [Cloudflare WorkersとNext.jsインテグレーションの問題にOpenNext実装が加わった - laiso](https://laiso.hatenablog.com/entry/2024/10/12/000528)\n\n概ねうまく動作しているように見えるのですが、Partial Prerendering が備え付けの `preview` コマンドだとうまく動作しませんでした。`next dev` や実際の Workers の環境では問題なく動作しているので、 Wrangler 特有の問題なのかもしれませんが、基本的な開発は `next dev` だと思うのであまり気にする必要はなさそうです。\n\n他にも現状だとサポートされていない機能がいくつかあって、特に ISR が使えないのが気になります。そのうち対応される気もするので使いたい場合は待つことになります。\n\n- https://opennext.js.org/cloudflare#supported-nextjs-features\n\n\n## Astro + Server Islands\n\n- [Astro · Cloudflare Workers docs](https://developers.cloudflare.com/workers/frameworks/framework-guides/astro/)\n\n```shell\nnpm create cloudflare@latest my-astro-app -- --framework=astro --experimental\n```\n\n`@astrojs/cloudflare` を使って動作します。\n\n- [@astrojs/cloudflare | Docs](https://docs.astro.build/ja/guides/integrations-guide/cloudflare/)\n\nServer Islands を試しましたが、問題なく動いているように思えました。個人的に Astro といえば SSG で、 GitHub Pages にデプロイすればいいかくらいの温度感で使っていたので、Workers で Server Islands が使えるのは出来ることが広がりそうだなという感触があります。この記事も Astro で書いたものを GitHub Pages においているのですが、そのうち Workers へ引っ越すかもしれません。\n\n- [Server islands | Docs](https://docs.astro.build/en/guides/server-islands/)\n\n直接今回の話とは関係ないのですが、Dev Container + OrbStack で `astro dev` で起動したサーバーにブラウザからアクセスができないという問題がありました。コンテナ内からの `curl` は通る状態です。Codespace や Dev Container でないローカル環境では動作するので、 OrbStack 特有の問題だと思いますが未解決です。Docker Desktop ですが次のような記事がありました。\n\n- [[mac]devcontainerで立ち上げたローカルサーバーに接続できない（built-in port-forwarding） #Docker - Qiita](https://qiita.com/hamu3864kA/items/353f14d456f6aa672c3b)\n\n## 雑感\n\nWorkers と Pages が徐々に統合されるという流れがあったと思うのですが、 Static Assets でこの流れが一気に進んだように思えます。出来るとわかりつつも、 Cloudflare Workers 上に Web UI をもつアプリケーションを作るのは少し億劫なところがあったのですが、 Static Assets が入るとそれが解決するので、個人開発レベルなら Cloudflare 1 本でも困ることがなくなりそうです。",
    "createdAt": "2025-02-02T00:00:00.000Z",
    "updatedAt": "2025-02-02T00:00:00.000Z",
    "publishedAt": "2025-02-02T00:00:00.000Z",
    "tags": [],
    "path": "/blog/cf-workers-static-assets-and-frameworks"
  },
  {
    "id": "cline-repository-refactoring",
    "title": "Cline でリポジトリ構造の変更とアーキテクチャのルール整備をした",
    "content": "個人的に作っているアプリで Feature Sliced Design (FSD) というアーキテクチャを途中から採用していて、導入以前に書かれたコードはそれに沿っていないという状態のリポジトリがあり、今回これを Cline を使ってこの移行を完了させようと思った。自分はこういう考えるところまではいいけど実際やるのはだるいな、みたいな作業こそ AI にやってもらいたいなと思っていたので題材としてちょうどいい感じだった。\n\n- https://github.com/feature-sliced\n- https://zenn.dev/moneyforward/articles/e1ed48c3974811\n\nどんなアプリかというと Chrome のサイドパネルとタブで動く GitHub の Issue/PR/Discussion リーダーで、分かる方は Jasper の Chrome 拡張版とイメージしてもらえるといいと思う。完全に自分用に作っているのでコードの公開とかは出来ないので、うまいこと察してほしい。アプリがわからなくとも話自体は分かるようにしているつもり。\n\n- https://jasperapp.io/\n\n## 前提\n\n- Tier 4 の 3.7 Sonnet\n- このリポジトリでの AI Coding は Cursor で少しだけ\n- TypeScript で、Biome を Linter/Formatter として使っている(いた)\n- Cline だけでやりきる\n- Memory Bank は個人のカスタマイズとして利用している\n\n## やりたいと思っていたこと\n\nこのリポジトリを今後 AI と滞りなく開発できるよう状態にしたい。一旦 Cline だとして、そのためには次の要素が必要だと考えた:\n\n- リポジトリの構造の完遂\n- FSD に沿った ESLint のルール追加\n- 既存コードへのテストの追加\n- .clinerules の整備\n\n現状は、 AI 向けのルールやガードレールが一切存在していないので、それも同時に整備することを目標にする。\n\n## 現状と目指す状態\n\n今はこんな感じに FSD に沿って書いたものと、それ以前に大きく lib と app(side-panel) に分けて書いていたものが混在している:\n```\nsrc/\n├── entities/ # FSD 導入後に書いたもの\n│   ├── github-search-result/\n│   │   ├── model/\n│   │   └── ui/\n│   └── timeline-item/\n│       ├── model/\n│       └── ui/\n│\n├── features/ # FSD 導入後に書いたもの\n│   └── timeline/\n│       └── model/\n│\n├── lib/ # FSD 導入以前のコードは大体ここにある\n│   ├── github/\n│   │   ├── gql/\n│   │   │   └── fragment/\n│   │   └── __fixtures__/\n│   └── stream.ts          # 主要ロジック\n│\n├── shared/ # FSD\n├── side-panel/ # この下に FSD 以前のアプリが作られている\n│   ├── components/\n│   │   ├── side-panel-content.tsx\n│   │   ├── side-panel-header.tsx\n│   │   └── side-panel.tsx\n│   ├── hooks/\n│   │   └── use-side-panel.ts\n│   ├── model/\n│   │   ├── side-panel-model.ts\n│   │   └── types.ts\n│   ├── store/\n│   │   └── side-panel-store.ts\n│   └── ui/\n│       └── side-panel-ui.tsx\n├── timeline/ # エントリーポイント類は FSD を反映していない\n└── worker/\n```\n\nこれをこんな感じに整理したい:\n\n```\nsrc/\n├── app/\n│   └── entries/\n│       ├── side-panel/\n│       │   ├── index.html\n│       │   └── index.tsx\n│       └── timeline/\n│           ├── index.html\n│           └── index.tsx\n│\n├── entities/\n│   ├── github-search-result/\n│   │   ├── api/\n│   │   │   └── gql/\n│   │   ├── model/\n│   │   │   ├── converters.ts\n│   │   │   ├── io.ts\n│   │   │   ├── timeline-item.ts\n│   │   │   └── type.ts\n│   │   └── ui/\n│   │       ├── detail.tsx\n│   │       ├── icons/\n│   │       └── timeline-item.tsx\n│   ├── stream/\n│   │   └── model/\n│   │       ├── keys.ts\n│   │       ├── query-helper.ts\n│   │       └── type.ts\n│   └── timeline/\n│       └── model/\n│           ├── io.ts\n│           └── type.ts\n│\n├── features/\n│   ├── stream-notifications/\n│   │   ├── api/\n│   │   │   └── gql/\n│   │   └── model/\n│   │       ├── events.ts\n│   │       ├── notifications.ts\n│   │       └── stream-management.ts\n│   └── timeline/\n│       └── model/\n│           ├── update-timeline.ts\n│           └── use-timeline.ts\n│\n├── pages/\n│   ├── side-panel/\n│   │   ├── model/\n│   │   │   └── use-notification-item.ts\n│   │   └── ui/\n│   │       └── page.tsx\n│   └── timeline/\n│       └── ui/\n│           └── page.tsx\n│\n├── shared/\n│   ├── config/\n│   │   └── types.ts\n│   └── lib/\n│       ├── browser/\n│       ├── event/\n│       ├── storage/\n│       └── time/\n│\n└── worker/\n    └── index.ts\n```\n\n## 基本的な作業の方針\n\n適当な作業の単位を 1 ループとして、そのループを次のような手順で進めた:\n\n1. Plan で実装、改修の方針を相談して決める\n2. その計画を Markdown として保存しておく\n3. Act で Markdown を計画として実行する\n    1. 必要な修正があれば適宜で修正をお願いする\n    2. コンテキストが足りなくなったり挙動が怪しくなったら、 Markdown を使って新しい Task に引き継ぐ\n4. 必要な修正が終わったら、その差分を Markdown に書き込ませてアップデート\n5. update memory bank 、書き足すところがあれば .clinerules もアップデート\n6. 適切なメッセージで git commit\n\n特徴として、 Plan の内容を逐一 Markdown として残しておく、というものがある。\nこれはもっと小さい範囲で試してみて、あとにドキュメントとして残せるしよさそう、という感触があったのでこれを採用してみることにした。\nこのファイルの作成ルールは `.clinerules` に書いている:\n\n```markdown\n## ドキュメント規約\n\n- `docs/plans/` - 計画ドキュメント\n  - ファイル名は `{3桁の通し番号}_{kebab-case-name}.md` の形式で保存\n```\n\nこれがある状態で、「計画を docs/plans に保存してから作業を始めてください」というような指示で ACT モードに切り替えると、その計画を保存してから進めてくれる。\n最終的には次の 17 個の計画で作業が終わった:\n\n```\nplans\n├── 001_migrate-from-biome-to-eslint-prettier.md\n├── 002_monorepo-removal-plan.md\n├── 003_migrate-to-jest-and-react-testing-library.md\n├── 004_feature-sliced-design-eslint-rules.md\n├── 005_test-implementation-plan.md\n├── 006_github-search-result-timeline-restructuring.md\n├── 007_lib-to-fsd-refactoring.md\n├── 008_timeline-to-fsd-refactoring.md\n├── 009_side-panel-to-fsd-refactoring.md\n├── 010_config-stream-type-refactoring.md\n├── 011_update-stream-refactoring.md\n├── 012_entities-to-features-reference-fix.md\n├── 013_created-at-type-fix.md\n├── 014_timeline-items-type-guard.md\n├── 015_other-type-errors-fix.md\n├── 016_side-panel-item-removal.md\n└── 017_timeline-api-call-fix.md\n```\n\n後から思ったこととして、もっと細かく分けるべきだったのと、指定と時系列の把握が楽になるので連番を使いたいが、複数人の場合にはコンフリクトのリスクがある。\n作業をしていく中で、元々の計画とのズレが生まれたら Markdown にその差分を追記してもらっていた:\n\n```\n今回の実装に、計画との差分があれば @mdfile に追記を行ってください。\n```\n\n\n他に意識したこととして、常に `.clinerules` を更新することを組み込んでいた。\nこれも作業が終わったあとに次のようなプロンプトで更新していた:\n\n```\n今回の作業内容で、 @.clinerules に記載すべきことがあれば追記してください。\n```\n\nこれはある程度ワークしていたように思うが、これは絶対入れてほしいなというルールが生まれたときは、その旨を随時お願いしていた。\n\n最後の git commit は、 `.clinerules` にフォーマットを書いて置くことで「commit して」というだけでいい感じにコミットメッセージを作ってくれるようにしていた:\n\n````markdown\n### コミットメッセージ規約\n```\n<type>(<scope>): <適切なメッセージ>\n\n- <詳細な変更内容>\n- <詳細な変更内容>\n```\n````\n\n## 実際の作業で特筆すべきところ\n\n大きめのポイントや詰まったところ、その解決を抜粋して書く。それぞれを細かく解説しているわけではない。\n\n### ESLint のルール作成関連\n\n#### 001_migrate-from-biome-to-eslint-prettier\n\nBiome から ESLint と Prettier に移行した、理由としてはカスタムルールが作りやすそうだったから。\nモジュール関連の地雷を多少踏みながらも滞りなく移行できて、さすがこういうのは得意という感じだった。\n\n#### 004_feature-sliced-design-eslint-rules\n\nその後、FSD に沿ったアーキテクチャになるよう ESLint のルールを Cline に作ってもらった。\nFSD のドキュメントやそこから抜粋した内容を渡して少し長めの Prompt から始めた。\n\n```\nこのリポジトリは Feature Sliced Design (FSD) の考え方を取り込んだ構造になっており、現在は既存のコードをそれに向けて移行している最中です。FSD については @https://feature-sliced.design/docs や @https://feature-sliced.design/docs/get-started/overview を参照してください。\n移行作業を進める前に、 ESLint でコードの配置に関するルールを作成します。\n次のルールを作成してください:\n\n- Layers は上から下にしか参照できないルール\n- Layers 配下には Slices が配置され、さらにその配下に Segments が配置され、適切なコードが置かれるルール\n\nただし、現在コードを移行中のため、ルールに該当しないディレクトリにあるコードはすべて無視してください。\n\n## Layers は上から下にしか参照できないルール\n\nコードは次のいずれかのレイヤーに配置されます:\n\n- app* — everything that makes the app run — routing, entrypoints, global styles, providers.\n- pages — full pages or large parts of a page in nested routing.\n- features — reused implementations of entire product features, i.e. actions that bring business value to the user.\n- entities — business entities that the project works with, like user or product.\n- shared* — reusable functionality, especially when it's detached from the specifics of the project/business, though not necessarily.\n\nこれは FSD の考え方から widgets と processes を省略したものです。\nレイヤー間の参照は上から下にしか行うことが出来ず、例えば pages から features のモジュールを import することは出来ますが、その逆は出来ません。同じレイヤーでの横の参照は許可されます。\nこのルールが守られていることを ESLint でチェックできるようにしてください。\n\n## Layers 配下には Slices が配置され、さらにその配下に Segments が配置され、適切なコードが置かれるルール\n\nFSD では pages, features, entities レイヤーの下に Slice が配置され、さらにその配下に Segment が配置されます。\nコードは任意の場所に配置出来ないため、このルールを守ることを ESLint でチェックできるようにしてください。\n\n公式から引用したルールは次のようになります:\nSlices\nNext up are slices, which partition the code by business domain. You're free to choose any names for them, and create as many as you wish. Slices make your codebase easier to navigate by keeping logically related modules close together.\n\nSlices cannot use other slices on the same layer, and that helps with high cohesion and low coupling.\n\nSegments\nSlices, as well as layers App and Shared, consist of segments, and segments group your code by its purpose. Segment names are not constrained by the standard, but there are several conventional names for the most common purposes:\n\nui — everything related to UI display: UI components, date formatters, styles, etc.\napi — backend interactions: request functions, data types, mappers, etc.\nmodel — the data model: schemas, interfaces, stores, and business logic.\nlib — library code that other modules on this slice need.\nconfig — configuration files and feature flags.\nUsually these segments are enough for most layers, you would only create your own segments in Shared or App, but this is not a rule.\n```\n\nCline と相談して、最終的に 5 つのルールを作ることになった:\n\n```\n# Feature Sliced Design (FSD) に基づいたESLintルールの実装\n\nFeature Sliced Design (FSD) アーキテクチャに基づいたESLintルールを実装しました。これにより、コードベースがFSDの原則に従っているかを自動的にチェックできるようになります。\n\n## 実装したルール\n\n###レイヤー間の参照ルール\n\n- 上位レイヤーから下位レイヤーへの参照のみ許可\n- app → pages → features → entities → shared の順で参照可能\n\n### 同一レイヤー内のSlice間参照禁止\n\n- 例：entities/userからentities/productへの参照は禁止\n\n### レイヤー構造ルール\n\n- appとsharedレイヤーは直接Segmentsを配置\n- pages, features, entitiesレイヤーはSlices配下にSegmentsを配置\n\n### Public API強制ルール\n\n- Sliceの内部実装を直接参照せず、公開APIのみを通じて参照\n- 例：import { Something } from '@src/entities/user'は許可\n- 例：import { Something } from '@src/entities/user/model/something'は禁止\n\n### バレルファイル内容検証ルール\n\n- index.tsファイルはimportとexportのみを含むべき\n- ロジックや実装詳細は含めない\n```\n\n注意点として、ESLint を作ろうとするときに広く使われている TIPS を取り込んだり、 ESLint のプラグインだと認識しているからかやたら汎用的なコードを書きたがる傾向があるように思う。\n前者としては、 `@src` のようないわゆる `paths` をこのリポジトリでは採用していなかったが、それが採用されているかのようなコードを書いていた。\n\n後者は、例えば設定を `eslint.config.js` で出来るようなコードを書こうとして、結果複雑になる上に動作しないような状態になっていた。\nこれは「設定ファイルで出来る必要はないし、シンプルにベタ書きで実装すればいいよ」というような指示をしてあげると、考えることが減るのかちゃんと動くコードが出てくる\n\nそんなこんなで ESLint を実行するとルールが適用され、 Cline が自身の書いたコードの誤りを検出できるようになった:\n\n```\n/workspaces/chrome-github-plugin/src/entities/github-search-result/ui/detail.tsx\n  1:1  error  Sliceの内部実装を直接参照せず、公開API(features/timeline)を通じて参照してください。各Sliceはindex.tsでのみ外部に公開されるべきです。               fsd/public-api\n  1:1  error  レイヤー 'entities' から上位レイヤー 'features' への参照は禁止されています。レイヤーは上から下にのみ参照可能です。                                fsd/layer-imports\n  2:1  error  同一レイヤー 'entities' 内の異なるスライス間の参照は禁止されています。スライス 'github-search-result' から 'timeline-item' への参照はできません。  fsd/slice-imports\n```\n### テストを作ってもらう\n\n#### 003_migrate-to-jest-and-react-testing-library\n\nテストが全く無かったわけではなく、動作確認程度に Node の組み込みランナーでテストは書いていたが、 AI が書いてくれるなら React もやるかということで Jest と React Testing Library へ移行してもらった。例によってモジュール関連でゴチャることがあるものの、概ね得意。\n\n#### 005_test-implementation-plan\n\n全部のコードのテストを書いてもらう計画を立てた。とはいえ、元々テストを書くことを考えて書いていないコードなので、コードを変更しないと書けないのであれば無視してよい、というルールにした:\n\n```\nsrc 以下のテストが書かれていないコードに対して単体テストを追加します。\nまた、node:test から Jest への移行が出来ていないテストがあれば、それを Jest へ移行してください。\n元のコードを変更することはせず、テストのためにコードを変更することは避けてください。\nテストを書くことが難しければ、無視して構いません。\n```\n\nが、実際には「細かく分けたらテストできそうなので分けました！」と分けてくることがありつらい。\n\nテストの内容を書いてもしょうもないのでそれは割愛する。テストの生成自体は全体的にはわりとうまくいくが、計画の実行方法に問題があり、すべてのテストを書くのでそれなりの計画になっているのだが、「計画を実行してください」だと途中で勝手に満足して終わってしまうということがあった。「いくつかのファイルに対してテストを追加・移行することができました。」ではなく全部やってほしい:\n\n```\n# テスト追加・移行完了レポート\nテスト追加・移行計画に基づいて作業を進め、いくつかのファイルに対してテストを追加・移行することができました。\n```\n\nここでは解決策として「すべてのステップが終わるまで続けて」とどの程度やってほしいのかを明確に伝えることでワークしたのだが、あとで思ったこととしてもっとタスクを分割するべきだった、というのがある。これは辻褄合わせフェーズではこの形を取ることにした。\n\n### コードの移動や分割\n\nこれ全般に言えることとして、テスト、Lint、型チェックを仮でもよいので全て通してからこの作業に入るべきだった、という反省がある。\n\n過去の経験から、多少テストや Lint が落ちている状態でも、その Task に関係がないものはうまく無視出来ている事が多く、今回もそれがうまく働いて最後に辻褄を合わせればよいだろう、と考えていた。今回は コアドメインの移動 → それを使うアプリの移動、という順番で移行を進めていたので、コアドメインが移動することでアプリからの参照が切れて、ビルドが通らなかったり型チェッ クが落ちるのは想定内。だがそれを「今回とは関係ないエラー」と認識していることがかなり多く、これはなるべく修正しながら進んでほしかった。\n\n結果としては最後の辻褄合わせで大した苦労はなく、移行としては成功しているのだが、途中でほとんどビルドが出来なかったりといったところでそれなりに不便があった。とはいえ最後にちゃんと合うなら全体としてみればよかったとも言えるので、少しむずかしいところだなと思う。まぁこのあたりは人間がやる場合でも変わらないのでは？と言われればそうなのだが。\n\n#### 002_monorepo-removal-plan\n\nこのリポジトリは元々 Monorepo になっていたのだが、このタイミングでルートへ統合した。大量にファイルを移動するを AI にやらせるは無駄だという肌感があったので、移動はこちらでやるということを明示して計画を立ててもらった。\n\n#### 007_lib-to-fsd-refactoring\n\n今回の肝で、適当に書いていたコードを FSD に沿って分割しながら再配置した。ぱっとイメージがあったわけではないので、分析して計画を大まかに立ててもらうところから始めた。\n\n```\n@/src/lib/ 以下のコードを FSD のルールにそって適切な構成に作り変えます。\nまずは大まかにプランを考えてください。\n```\n\nいろいろ相談していったのだが要点としては以下:\n\n- 似たような概念が FSD と lib それぞれに存在していて、これらを別々のものとして扱おうとしていたので、統合してもらうようにした\n- アプリのドメイン知識が足りずに Notification を一般的な通知機能だと思い込み独立させようとしていた、これはこのアプリでは少し違う概念なので軌道修正した\n    - これはアプリ内では「更新があったIssue」くらいの意味で使われていた\n- GraphQL の query の扱い方を相談して決めた\n\n計画が出来たら、細かいステップに分割してとお願いした後に、適当な単位で git commit するようにお願いしていた(これは `.clinerules` に含める以前の話):\n\n```\n計画の詳細さは維持したまま小さいステップに分割して\n```\n\n```\n各ステップで git commit を行うようにしてください、フォーマットは以下\n\ngit add .\ngit commit -am \"refactor: <適切なメッセージ>\n\n- 詳細\n- 詳細\n- 詳細\n\"\n```\n\nで、これがうまく行ったかというと前述した通りあまりうまくいかなくて、途中まで進めて満足したのか止まってしまう。\nステップごとの git commit も途中まではうまく行っていたのだけど、一度止まったあとに再開させるとその指示が Markdown に含まれているのにもかかわらず忘れてしまったりで、ぐぬぬという感じだった。\n今回は Cline 自体の検証も兼ねているので、満足行くような動きをするまでこのフェーズを何度かやり直していて、実装フェーズの実行だけで合計 $30 くらい吹き飛んでいった。つらい。\n\n結果としてはここは「チェックリストを別ファイルとして作ってアップデートしながらやって」というのがある程度ワークしていてやり切ることは出来たのだが、更新のタイミングがまちまちだったりしてあまりおすすめできる感じではなかった。ちゃんと更新のルールをつめてあげるとか、Roo Code であればそういう Mode を作ればうまくいきそうという感じはしたが、あまりおすすめできない感じ。こんなプロンプトでやっていた:\n\n````\n@/docs/plans/007_lib-to-fsd-refactoring.md に沿って、 src/lib 以下を FSD に準じたコードにする作業を進めます。\n最初に docs/checklist.md として詳細な作業のチェックリストを作ってください。ステップ毎の作業は以下の手順で進めるようにしてください。\n\n```\n1.  pnpm test を実行し、前の作業が問題を残していないことを確認する\n2. 各ステップの実装を行う\n3. 単体テスト: `pnpm test -- <作業したディレクトリ>`\n4. 型チェック: `pnpm tsc --noEmit`\n5. リンティング: `pnpm lint <作業したディレクトリ>`\n6. 関連テスト: 作業内容に影響を受ける可能性のある他のテストを実行\n7. 以下の形式で変更をすべて git commit\n\nrefactor: <適切なメッセージ>\n\n- 詳細な変更点\n- 詳細な変更点\n- 詳細な変更点\n```\n\n以後何か作業を進めるごとに必ずこのチェックリストを更新しながら進めます。\n準備が出来たら、すべてのステップの作業が完了するまで作業を続けてください。\n````\n\n一方でモデルの統合は計画で時間を書けたからかうまくやってくれていた、えらい。\nあとはテストを移行するのを忘れるので、ちゃんと指示に含めたほうがよさそうだった。\n\n### 辻褄合わせフェーズ\n\n010 以降がこれにあたり、前述通り計画が大きすぎた反省を活かして、 Plan としては「pnpm eslint を実行して全部直して」くらいのものから始めるが、計画を保存するときに具体的な内容で分割して保存するようにした:\n\n```\ndeleteLogic と ConfigStream へのリネームに関する作業計画と、 updateStreamの呼び出しに関する作業計画をそれぞれ docs/plans に書き出してください\n```\n\nこうすると 010 と 011 に計画を分けてくれたので、小さくなった個別の Task をそれぞれ実行させて完了させていった。番号のつけ方はともかく、これは結構うまく行ったように思う。\n\n## .clinerules\n\n終盤になって `.clinerules` にある程度情報が溜まった来たところで `.clinerules` をブラッシュアップさせた:\n\n```\n@/.clinerules をよりよいものにアップデートしたいと考えています。\nより良いとは、次のような基準です。\n\n- 明確かつ簡潔であること\n- 全体のトーンが揃っていること\n- 重要なアーキテクチャの核心についてはより詳しく書かれていること\n- 特殊な表記を使わず、見出し、段落、箇条書き、リストを中心とした、人にも読みやすいシンプルな構成\n- 記載されている順序がよく練られており、上から順に読めば開発に着手できる\n\nまた、次のような要素を付け加えたいと考えています。\n\n- 簡単なコードを書くこと\n- 早期リターンを意識しフラットな構造にする\n- 関数で書くことを優先する\n- ...\n\nよりよい .clinerules が作れるよう、コードベースも参考にして考えてください。\n```\n\n最終的には次のような内容になった:\n\n````\n# プロジェクトルール\n\n## 重要\n\n1. コード変更前にテストを確認し、実行する\n2. テストで期待する動作を事前に定義する\n3. コード作成後、テストと静的解析を実行\n4. 3回連続で問題解決できない場合、ユーザーに相談する\n\n## 開発ワークフロー\n\n### コマンド一覧\n- **開発サーバー起動**: `pnpm dev`\n- **ビルド**: `pnpm build`\n- **テスト実行**: `pnpm test`\n  - 特定のテストファイル実行: `pnpm test -- <filename>`\n- **テスト（監視モード）**: `pnpm test:watch`\n- **テストカバレッジ**: `pnpm test:coverage`\n- **リンティング**: `pnpm lint`\n  - 特定ファイルのリント: `pnpm lint -- <filename>`\n- **コード自動修正**: `pnpm lint:fix`\n- **フォーマット**: `pnpm format`\n\n### 開発フロー\n1. **機能実装前**: テストを先に書く（TDD）\n2. **コード変更時**: 既存テストが通ることを確認\n3. **コード作成後**: テストを実行して期待通りの動作を確認\n   ```bash\n   pnpm test -- <filename>  # 特定のファイルのテストを実行\n   # または\n   pnpm test                # すべてのテストを実行\n   ```\n4. **テスト失敗時**: テストが通るようにコードを修正\n5. **リファクタリング時**: テストが引き続き通ることを確認\n6. **コミット前**: ESLintを実行してコードスタイルを確認\n   ```bash\n   pnpm lint\n   pnpm lint:fix  # 自動修正可能な問題を修正\n   ```\n\n### 拡張機能のロード方法\n1. Chromeで`chrome://extensions`を開く\n2. デベロッパーモードを有効化\n3. `packages/extention/dist`ディレクトリを読み込む\n\n### コミットメッセージ規約\n```\n<type>(<scope>): <適切なメッセージ>\n\n- <詳細な変更内容>\n- <詳細な変更内容>\n```\n\n## 開発の基本原則\n\n### コード品質\n- **シンプルなコード**: 複雑な実装より読みやすいコードを優先\n- **早期リターン**: 条件分岐はネストを避け、早期リターンでフラットな構造に\n  ```typescript\n  // 良い例\n  function processItem(item) {\n    if (!item) return null;\n    if (item.isInvalid) return null;\n\n    return transformItem(item);\n  }\n\n  // 避けるべき例\n  function processItem(item) {\n    if (item) {\n      if (!item.isInvalid) {\n        return transformItem(item);\n      }\n    }\n    return null;\n  }\n  ```\n\n### 関数型アプローチ\n- **関数優先**: クラスよりも関数で実装\n- **純粋関数**: 副作用を持たない関数を優先\n- **ループ処理**: `forEach`を避け、`for...of`または配列メソッドを使用\n  ```typescript\n  // 良い例（非同期処理の場合）\n  for (const item of items) {\n    await processItem(item);\n  }\n\n  // 良い例（同期処理の場合）\n  const results = items.map(item => processItem(item));\n\n  // 避けるべき例\n  items.forEach(async (item) => {\n    await processItem(item); // 非同期処理の制御が難しい\n  });\n  ```\n\n### 依存管理\n- **依存の最小化**: 可能な限りリポジトリ内のコードで解決\n- **依存追加時**: 必ずユーザーに確認\n- **外部依存のモック**: テスト時に外部依存を適切にモック化\n\n### 抽象化\n- **過度な抽象化を避ける**: 具体的で理解しやすいコードを優先\n- **Sliceの具体性**: 抽象的なコードよりも具体的な実装を優先\n\n## アーキテクチャ（Feature Sliced Design）\n\n### レイヤー構造\n1. **app** — アプリケーション実行に必要な要素\n   - エントリーポイント、グローバルスタイル、ルーティング\n2. **pages** — 完全なページまたはネストされたページ部分\n3. **features** — ユーザーにビジネス価値をもたらす機能\n4. **entities** — ビジネスエンティティ（GitHub Search Result、Timeline Itemなど）\n5. **shared** — 再利用可能な機能（プロジェクト/ビジネスから独立）\n\n### 参照ルール\n- 上位レイヤーから下位レイヤーへの参照のみ許可\n  - `app` → `pages` → `features` → `entities` → `shared`\n- 下位レイヤーから上位レイヤーへの参照は禁止\n- 同一レイヤー内のSlice間の参照も禁止\n\n### Slice構造\n- **app**と**shared**レイヤーは直接Segmentsを配置\n- **pages**, **features**, **entities**レイヤーはSlices配下にSegmentsを配置\n\n### Segment構造\n- **ui** — UI表示（コンポーネント、スタイルなど）\n- **model** — データモデル（スキーマ、ロジックなど）\n- **api** — バックエンド連携（リクエスト関数など）\n- **lib** — 他のモジュールが必要とするライブラリコード\n- **config** — 設定ファイルとフラグ\n\n### Public API\n- 各Sliceの公開APIはindex.tsで明示的にエクスポート\n- Sliceの内部実装詳細を直接参照することは禁止\n- 各sliceの直下には必ずindex.tsファイルを配置\n\n```typescript\n// entities/github-search-result/index.ts\nexport * from './api';\nexport * from './model/io';\nexport * from './model/timeline-item';\nexport * from './model/type';\nexport * from './ui/detail';\n// ...\n```\n\n## コーディング規約\n\n### TypeScript\n- 型定義を厳格に行う\n- 型ガード関数を活用して型安全性を確保\n  ```typescript\n  function isCommentTimelineItem(item: any): item is CommentTimelineItem {\n    return item.type === 'IssueComment' && 'bodyText' in item;\n  }\n  ```\n\n### Reactコンポーネント\n- 関数コンポーネントとして実装\n- Reactフックを活用\n- プロパティベースの設計（下位レイヤーのコンポーネントは上位レイヤーの機能を直接参照しない）\n\n### スタイリング\n- CSSモジュールを使用してスタイルをコンポーネントスコープに保つ\n  ```typescript\n  import styles from './component.module.css';\n\n  function Component() {\n    return <div className={styles.container}>...</div>;\n  }\n  ```\n\n### ファイル命名\n- ファイル名はキャメルケースを使用\n- テストファイルは`.spec.ts(x)`という命名規則\n\n### インポート\n- 相対パスのみ使用（エイリアスは使用しない）\n- パス記法は`./{path}`、`../{path}`のみ\n  ```typescript\n  // 良い例\n  import { Button } from '../../shared/ui/button';\n\n  // 避けるべき例\n  import { Button } from '@shared/ui/button';\n  ```\n\n## 実装パターン\n\n### ストリーム更新パターン\n- `updateStream`関数でGitHubからデータを取得\n- 各ストリームは`onUpdateThisLoop`関数で更新タイミングを制御\n- 更新後は`notifyUpdated`でイベントを発行\n\n```typescript\nexport const updateStream = async (name: keyof typeof streams, storage: Storage) => {\n  // データ取得ロジック\n  // ...\n\n  // 通知条件の判定\n  if (item.type === 'Issue' && shouldNotifyIssue(item, 'username', lastUpdated)) {\n    createNotificationIfNeeds(storage, item.id, lastUpdated);\n  }\n\n  // ストレージ更新\n  await Promise.all([\n    setToStorage(storage, keyForItem(item.id), item),\n    setToStorage(storage, keyForStreamItems(stream), newIds),\n  ]);\n\n  // イベント発行\n  notifyUpdated(name, updatedIds);\n};\n```\n\n### ストレージ管理パターン\n- キーは`keyFor*`関数で生成（一貫性のため）\n- `getFromStorageOrDefault`と`setToStorage`を使用\n- アイテムIDをリストとして保存し、実際のデータは個別に保存\n\n```typescript\nconst ids = await getFromStorageOrDefault(storage, keyForStreamItems(stream), () => []);\nconst items = [];\n\nfor (const id of ids) {\n  const item = await getFromStorageOrDefault(storage, keyForItem(id), () => null);\n  if (item) {\n    items.push(item);\n  }\n}\n```\n\n### 通知システム\n- `shouldNotifyIssue`と`shouldNotifyDiscussion`で通知条件を判定\n- `createNotificationIfNeeds`で通知を作成\n- `notifyNotificationUpdated`でイベントを発行\n\n### イベント処理\n- カスタムイベント（`stream:updated`、`notification:updated`）を使用\n- `subscribeStreamUpdated`と`subscribeNotificationUpdated`で購読\n\n```typescript\n// イベント発行\nexport const notifyUpdated = (name: string, ids: string[], worker = false) => {\n  dispatchUpdate('stream:updated', { name, ids }, worker);\n};\n\n// イベント購読\nuseEffect(() => {\n  const unsubscribe = subscribeStreamUpdated(({ name }) => {\n    if (name === streamName) {\n      fetchData();\n    }\n  });\n\n  return () => unsubscribe();\n}, [streamName, fetchData]);\n```\n\n### プロパティベースのコンポーネント設計\n- FSDレイヤー間参照ルールに従うため、下位レイヤー（entities）のコンポーネントは上位レイヤー（features）の機能を直接参照しない\n- 通知状態などの機能は上位レイヤーからプロパティとして注入する\n- 例: `IssueLine`コンポーネントは`hasNotification`や`onDeleteNotification`をプロパティとして受け取る\n\n### 非同期処理パターン\n- async/awaitを使用した読みやすい非同期コード\n- Promise.allを使用した並列処理\n- for...ofループを使用した非同期処理（forEachではなく）\n\n```typescript\n// 並列処理\nconst results = await Promise.all(\n  queries.map(query => fetchData(query))\n);\n\n// 順次処理\nfor (const item of items) {\n  await processItem(item);\n}\n```\n\n## テスト戦略\n\n### テストファイルの配置\n- 実装ファイルと同じディレクトリに配置\n- `.spec.ts(x)`という命名規則を使用\n\n### テストファースト\n- テストを先に書くことで、仕様を明確にする\n- 実装前にテストを書くことで、APIや動作の設計が洗練される\n- テストが通るように実装することで、要件を満たす保証になる\n\n### テスティングトロフィー\n- テスティングトロフィーを意識し、過度なモック化は避ける\n- 単体テスト、統合テスト、E2Eテストのバランスを考慮\n- 実際のユーザー体験に近いテストを優先\n- モックは必要最小限にとどめ、可能な限り実際の実装を使用\n\n### テスト関数\n- `test`関数を使用（`describe`や`it`は使用しない）\n- 日本語でテスト内容を記述\n\n```typescript\ntest('初期状態ではpendingがtrueで、データ取得後にfalseになる', async () => {\n  // テスト実装\n});\n```\n\n### モックの活用\n- Jestのモック機能を使用\n- 外部依存関係を適切にモック化\n- 過度なモック化は避け、実際の動作を反映したテストを心がける\n\n```typescript\njest.mock('../../../entities/timeline/model/io');\njest.mock('../../../shared/lib/event');\n\nbeforeEach(() => {\n  (timelineIO.getTimeline as jest.Mock).mockResolvedValue(mockTimeline);\n});\n```\n\n### UIコンポーネントテスト\n- React Testing Libraryを使用\n- レンダリングの検証\n- ユーザーイベントのシミュレーション\n- アクセシビリティを考慮したセレクタの使用\n\n```typescript\ntest('「Show all events」ボタンをクリックするとすべてのイベントが表示される', () => {\n  render(<TimelineItems items={items} />);\n\n  // ボタンをクリック\n  fireEvent.click(screen.getByText(/Show all events/));\n\n  // 表示を検証\n  expect(screen.getByText(/testUser commented/)).toBeInTheDocument();\n});\n```\n\n## コメント規約\n\n- `TODO`: 将来的に実装すべき機能\n- `MEMO`: 実装の背景や理由の説明\n\n## ドキュメント規約\n\n- `docs/plans/` - 計画ドキュメント\n  - ファイル名は `{3桁の通し番号}_{kebab-case-name}.md` の形式で保存\n\n## 制約と注意点\n\n### GitHub API制限\n- レート制限に注意（短時間に多数のリクエストを送らない）\n- エラーハンドリングを適切に実装\n\n### サービスワーカー制約\n- サービスワーカーのライフサイクルに注意（長時間実行できない）\n- 定期的なウェイクアップと処理の分散\n\n### 既知の問題\n- ユーザー名がハードコードされている箇所がある（将来的に設定から取得するよう変更予定）\n- 初回データ取得時の挙動に制限あり\n````\n\nちなみにこれを書いている途中に `.clinerules` が[ディレクトリにできるようになった](https://x.com/cline/status/1901778415931580550)。\n\n## 所感\n\n### 計画の管理方法と区切り方\n\n管理方法に関しては答えがあまり考えられていないのだけど、計画の Markdown を中心に回すのは自分としては好みのフローだった。\nフロー以外にも、想定していないとか動作がおかしなコードが見つかったときに、それがどこで生まれたかを Markdown を遡って探しに行ってくれていたりして、そういう意味もあったほうがいいのだとは思う。\nとはいえ、ちょっとした bugfix まですべて管理したいのかと言われるとそうでもなく、 PR の単位で一つあればいいような温度感なので、 Plan というよりは Design Doc のような感覚で残せるといいのかなと思う。\n\n番号は指定が楽になるので割とほしくて、複数人で管理する場合はやはり GitHub Issue などに連携できるとよさそう。そうするとそれをフロー化した Roo Code のカスタムモードが使いたくなるな、という感じだった。\n\n実際の管理方法をどのようにしていくかにもよるが、計画自体は思っている 3 倍くらいは細かくしたほうがいいなと思った。 Design Doc のような形にする場合は、あまり分かれすぎていても効果が薄そうなので、 Git 管理下にない場所で個人的に使うのも手かもしれない。\n\n### Lint は AI に整備させる\n\n結構ちゃんとしたものがすぐに出てくるので便利。\n汎用的なものを作ろうとする傾向にあるように思うので、局所最適して良いことを伝えると精度が上がるように思う。\n\n### 多分作り直させたほうがいい\n\n既存のコードを大きく書き換えるよりも、既存のコードを解析させて仕様抽出、その仕様をもとに新しいコードを生成させる方が得意だろうと思うので、今回のように Cline で移動させるみたいなのはあんまり向いていない気もする。\n途中でやり直しているフェーズがいくつかあるとはいえ、やり切るのに大体 $100 かかっていて、「これ作り直したほうが安くね？」と思いながらやっていた。\n\n### 名前を横着せずにちゃんとつける\n\n別に人間がコードを書く場合でも変わらない話ではあるが、抽象度が高い名前を使っていると勝手に役割を推測されているような感覚があった。\n新しく作る場合よりは、既存のコードを解析させたりリファクタリングさせる場合にこれは大きく影響してきそう、という肌感。",
    "createdAt": "2025-03-19T00:00:00.000Z",
    "updatedAt": "2025-03-19T00:00:00.000Z",
    "publishedAt": "2025-03-19T00:00:00.000Z",
    "tags": [],
    "path": "/blog/cline-repository-refactoring"
  },
  {
    "id": "clinerules-and-memory-bank",
    "title": "2025年3月時点での Memory Bank と .clinerules の使い分けに関する考え",
    "content": "Cline (Roo Code) を使っているとよく出てくる概念として Memory Bank というものがある。\n\n- https://docs.cline.bot/improving-your-prompting-skills/custom-instructions-library/cline-memory-bank\n\nこれのコンセプトはなんとなく理解できるものの、「じゃあ .clinerules との使い分けはどうなんだ」「Memory Bank は commit するべきなのか？」というのがあまり分かっていなくて、そこにフォーカスして考えた内容。\n\nこれを書いている 2025 年 3 月初旬時点の頭の中をダンプした個人的な記録で、完全に間違っているかもしれないし 1 週間後にはまったく違うことを言っているかもしれない、というものなのでご了承いただきたい。また、基本的にはコードを複数人で触ることを前提として考えている。\n\nここでは特に Cline の Memory Bank について書いて、基本的なコンセプトなどは分かっているものだとする。解説がほしい方は以下の記事がおすすめ。\n\n- https://zenn.dev/katonium/articles/cline-memorybank-poem\n\nRoo Code 向けの Memory Bank として以下のものがあることは知っているが、使ったことはない。\n\n- https://github.com/GreatScottyMac/roo-code-memory-bank/tree/main\n\n## 現時点での使い分け\n\n「`.clinerules` をリポジトリに含めて育て、 Memory Bank は個人をサポートするツールとして利用する」に自分の中で落ち着いた。\n\n### .clinerules\n\nこれに記載するべき内容については散々各所で言われていると思うので割愛する。\nGit などの管理下において共有し、これがあれば Cline での開発を進めることができるだろう、という状態を目指したい。\n基本的には人間が記述し管理する、もしくは AI が生成したものを人間が編集しレビューする、という形で運用する。\n\n### Memory Bank\n\nMemory Bank は個人のカスタムプロンプトとして利用して、その成果物を共有しない。\n個人がどのように使うか、そもそも使うか使わないかも管理しないことにする。\n生成されたドキュメントをどこで管理するかというの問題があるが、個人で gitignore してもらうか、配置場所のルールを決めてそこを gitignore しておく。\n\n## なんでそう思ったか\n\n### Memory Bank は出力が安定しているわけではない\n\nこれは自分の設定や使い方の問題の可能性があるが、Memory Bank の出力する md ファイルは毎回同じ内容が安定して手に入るわけではない、という認識をしている。\nある意味当たり前の話ではあるのだが、ある程度コードのあるリポジトリで何度か作り直したりすると、毎回違うものが出てくる。\n違うといっても主にフォーマットや言葉遣いの話で主要なところはだいたい似通っているのだけど、なんにせよこれを共有したいかというとそういう気にはならなかった。うまくプロンプトを書けば安定が手に入る...のかもしれない。\n\n### activeContext や progress は完全に個人の作業状況に依存する\n\nという認識をしている。共有したいものではないし、これを共有するよりは Plan や Architect の出力をリポジトリに含める方が、他の人があとから参照させることもできたりして効果が高そう。\n\n### Memory Bank は .clinerules も見てくれる\n\nupdate memory bank を行うときに、 .clinerules があればその内容を考慮した Memory Bank が生成されているはずで、より不変な知識は .clinerules に任せるのがよいのだと思う。\n一方でこれを AI の生成に完全に任せてしまうと、出力が安定しないのでコンフリクト祭り... となりそう。\n\n### Cursor の Project Rules との共存\n\n現状だと個人の好みも込みで、 Cursor が共存することが多いと考えていて、実際自分も Cursor の中で Roo Code を動かしている。\nCursor には、少なくとも自分の知る限りでは Memory Bank に相当するものはなく、基本的には Project Rules で AI を制御する形になっている。\nこの運用としてそれぞれの rules 系ファイルを個別に管理するのではなく、ベースとなるものは同一にし、それをそれぞれの形式に加工するスクリプトを用意するような形が想定される。\nそこで Memory Bank よりは近い性質をもつ .clinerules が管理されているべきだと思う。\n\n## 逆に一人しか触らない個人での開発ならどうなのか？\n\nこれは Cline しか使わないなら、 Memory Bank だけで十分なのではないかと思う。 Memory Bank を運用していく中で、不変なものは .clinerules に蒸留していくような形にするのが良いと思う。",
    "createdAt": "2025-03-13T00:00:00.000Z",
    "updatedAt": "2025-03-13T00:00:00.000Z",
    "publishedAt": "2025-03-13T00:00:00.000Z",
    "tags": [],
    "path": "/blog/clinerules-and-memory-bank"
  },
  {
    "id": "roo-code-issue-hunter",
    "title": "Roo Code で GitHub Issue を解決しようとしてくれる Custom Mode を作る",
    "content": "Roo Code は Code や Architect といった標準のモードの他に、自分で Custom Mode を作ることができる。これを gh コマンドと組み合わせれば、 GitHub から Issue を拾ってきて、それを解決するような Custom Mode を作ることが出来そうだったので試した。\n\n- https://docs.roocode.com/advanced-usage/custom-modes/\n- https://docs.github.com/ja/github-cli/github-cli/about-github-cli\n\n## 前提\n\n- Tier 4 の 3.7 Sonnet (thinking)\n- Cursor Pro を使うこともある\n- Dev Container での開発\n    - `features` で `ghcr.io/devcontainers/features/github-cli` を入れている\n- この時点では精度にはあまり期待していない、参考になる何かができるか手を付けるきっかけになれば嬉しい、というモチベ\n    - Issue の品質にもバラつきがあるので\n\n## 動くか試す\n\n`issue list` と `issue view` は次のような出力をするので、これを食わせれば Issue が読めそう:\n\n```\n$ gh issue list\n\nShowing 13 of 13 open issues in yaakaito/yaakaito\n\nID   TITLE                                                             LABELS  UPDATED\n#55  注釈は Pop Over で Top Layer に出すようにする                             about 5 hours ago\n#54  アイキャッチ画像を最終的に合成する際、目安の線を引く                      about 5 hours ago\n#53  モチーフと背景色は、それが何を表しているかの対応表を表示する              about 5 hours ago\n....\n```\n\n```\n$ gh issue view 47\n\nアイキャッチ画像は生成に AI が関係していることをわかるようにする #47\nOpen • yaakaito opened about 11 hours ago • 0 comments\n\n\n\n  • 画像の右下に i マークをつけて、「AI が作ったものを人間が加工している」といった旨を表示するようにする\n  • GitHub Issue へのリンクを用意して、問題があれば報告できるようにする\n  • 専用の Issue テンプレートを用意する\n\n\nView this issue on GitHub: https://github.com/yaakaito/yaakaito/issues/47\n```\n\nCode モードで gh の使い方を教えながら Issue を解決できるかを試した:\n\n<img src=\"/images/roo-code-issue-hunter-mode-01.png\">\n<img src=\"/images/roo-code-issue-hunter-mode-02.png\">\n\nこれでもう修正を始めてくれた、えらい。残りはいつもの Code なので割愛。\n\n\n## Custom Mode にする\n\n考えた手順がそのままプロンプトなので完成品、名前は `Issue Hunter` にした:\n\n````\nYou are Roo, a highly skilled software developer with extensive knowledge, specializing in analyzing GitHub Issues, solving problems, and implementing fixes.\n\n1. Run `gh issue list` to check currently active issues\n2. Check `.issue-hunter.md` to review issues you have already attempted to fix\n3. Run `gh pr list` to check if there are any existing Pull Requests for fixes\n4. Select an issue that the user requests, or choose one you can handle if the user doesn't specify\n5. View issue details using `gh issue view {id}`\n6. Create a detailed plan to accomplish the task based on the issue details. While you should work independently, ask the user clarifying questions if anything is unclear\n7. Before making changes, create a branch using `git switch -c fix/{id}`\n8. Implement the solution according to your plan\n9. When implementation is complete, create a git commit with the following format:\n\n```\n{appropriate commit message} fix #{id}\nDetails of the plan\nDetails of the plan\nDetails of the plan\n```\n\n10. After `git commit`, push the current branch using `git push origin fix/{id}`\n11. After pushing, create a Pull Request using `gh pr create`\n12. Write a concise summary of your work in `.issue-hunter.md` - this file is used to track which issues you have resolved\n13. Return to the main branch using `git switch main`\n````\n\nこれの日本語版も貼っておく、ちなみに「日本語 → Sonnet → 英語 → Sonnet → 日本語」でシステムプロンプトであることを考慮して出力して、とお願いしたもの:\n\n````\nあなたはRooであり、GitHub Issueの分析、問題解決、修正の実装を専門とする高度な知識を持つ熟練したソフトウェア開発者です。\n\n1. `gh issue list`を実行して、現在アクティブなIssueを確認します\n2. `.issue-hunter.md`を確認して、すでにあなたが修正を試みたIssueを確認します\n3. `gh pr list`を実行し、すでに修正のためのPull Requestがないかを確認します\n4. ユーザーが求めるIssueがあればそれを、そうでなければあなたがこなせそうなIssueを選択して解決します\n5. Issueの詳細は`gh issue view {id}`で確認できます\n6. Issueの詳細を見てタスクを達成するための詳細な計画を立てます。これは基本的にあなたが自立して行うべきですが、内容が不明瞭だったり、質問がある場合はユーザーに明確化のための質問をするべきです\n7. 修正を行う前に`git switch -c fix/{id}`でブランチを作成してください\n8. 計画に沿って実装を行ってください\n9. 実装が終わったら、次のフォーマットで`git commit`してください：\n\n```\n{適切なコミットメッセージ} fix #{id}\n計画の詳細\n計画の詳細\n計画の詳細\n```\n\n10. `git commit`したら、現在のブランチを`git push origin fix/{id}`でプッシュします\n11. プッシュしたら`gh pr create`でPull Requestを作成します\n12. `.issue-hunter.md`に今回の作業を簡潔に書き込んでください、これはあなたがIssueの解決状況を把握するために使用するファイルです\n13. ブランチを`git switch main`でmainに戻してください\n````\n\n最初は 2 と 3 がなくて、新しい Task になるとまた同じ Issue を直そうとしていたのでやったことを残してもらうようにした、このファイルは gitignore する前提。もし使う場合はパスとか名前はよしなにしてほしい。\n\n元々あと一行「14. 特別な指示がなければ、次のIssueを解決するために積極的に手順1から繰り返し、継続的に問題を解決し続けてください」というのがあったが、動いたり動かなかったりするのと、修正中に作ったゴミが残ったりなんかして、 Git がごちゃごちゃすることがあったのでやめた。連続でいくつか直すのは Task での入力で多分できる。\n\n### 適当に何か直させる\n\nこれで「なんかなおして」とかお願いすると、まだ着手してなさそうな Issue を探して作業を始めてくれる。参考までにこれを書いている時点では `gh issue list` はこんな感じになっている:\n\n```\n$ gh issue list\n\nShowing 13 of 13 open issues in yaakaito/yaakaito\n\nID   TITLE                                                             LABELS  UPDATED\n#55  注釈は Pop Over で Top Layer に出すようにする                             about 5 hours ago\n#54  アイキャッチ画像を最終的に合成する際、目安の線を引く                      about 5 hours ago\n#53  モチーフと背景色は、それが何を表しているかの対応表を表示する              about 5 hours ago\n#52  倍率を 12x も選べるようにする                                             about 6 hours ago\n#51  アイキャッチのモチーフを強制的に選べるように                              about 6 hours ago\n#50  背景色候補のトーンを下げる、サンプルを作る                                about 6 hours ago\n#49  背景を全く違う色で塗りつぶす機能が必要そう                                about 6 hours ago\n#48  コードブロックが長い場合に折り畳めるようにする                            about 9 hours ago\n#47  アイキャッチ画像は生成に AI が関係していることをわかるようにする          about 11 hours ago\n#46  note/9 が 404 になる                                                      about 1 day ago\n#44  Vectroize への登録を差分化する                                            about 7 days ago\n#41  投稿は archive として一元化し、タグでカテゴリを管理する                   about 25 days ago\n#36  Note の emoji にバリエーションをつける                                    about 1 month ago\n```\n\n```\nなんかなおして\n```\n\nやれそうな Issue を見つけてくる:\n\n<img src=\"/images/roo-code-issue-hunter-mode-03.png\">\n\n直すところは Code モードと大して変わらないので割愛。変更が完了したら、commit して push して .issue-hunter.md を更新してくれる:\n\n<img src=\"/images/roo-code-issue-hunter-mode-04.png\">\n\nPR も作ってくれて、 main に戻ってきて終わり:\n\n<img src=\"/images/roo-code-issue-hunter-mode-05.png\">\n\n出来た Pull request はこれ、ちなみにやることはちゃんと間違えていて、そういうことではないという感じではある:\n\n- https://github.com/yaakaito/yaakaito/pull/65\n\n他のものも直してほしいのでお願いする:\n\n```\nもっとやって\n```\n\n<img src=\"/images/roo-code-issue-hunter-mode-06.png\">\n\n新しい Issue を探してきて直してくれる、このあと連続でもう一つ直してくれて、合計 3 つの PR を作ってくれた:\n\n<img src=\"/images/roo-code-issue-hunter-mode-07.png\">\n\n出来た Pull request (差分):\n\n- https://github.com/yaakaito/yaakaito/pull/66\n- https://github.com/yaakaito/yaakaito/pull/67\n\n### 直してほしいやつを直してもらう\n\n例えば「#52  倍率を 12x も選べるようにする」を直してもらいたければ、「倍率のやつ直して」とかで通じる:\n\n<img src=\"/images/roo-code-issue-hunter-mode-08.png\">\n<img src=\"/images/roo-code-issue-hunter-mode-09.png\">\n\n- https://github.com/yaakaito/yaakaito/pull/68\n\n## 雑感\n\n- Issue を整備しておけばそれなりの精度で勝手に直してくれるので、これまで腰が重かったものにも手を出せるようになりそう\n    - フォーマット化して、曖昧なことを書いていないかなんかを CI で lint させたりして、事前にブラッシュアップできると良さそう\n- 今回何が答えかわかりにくいブログというコードで試しているけど、ガードレールがきちんとしたリポジトリであれば結構精度良く直してくれそう\n- とりあえず暇なときに動かしておく、とかでも Issue に取り組むきっかけになるのでよさそう",
    "createdAt": "2025-03-06T00:00:00.000Z",
    "updatedAt": "2025-03-06T00:00:00.000Z",
    "publishedAt": "2025-03-06T00:00:00.000Z",
    "tags": [],
    "path": "/blog/roo-code-issue-hunter"
  },
  {
    "id": "blog-redesign-with-architect",
    "title": "Roo Code の Architect で計画を立ててこのブログをリデザインする",
    "content": "これまでここには自分用のまとめくらいにしか記事を書いていなかったのでデザインもかなり適当だったのですが、[前回](https://yaakai.to/blog/2025/create-eye-catching-visuals-with-ai/)の記事をきっかけに人が見られるレベルにしたいなと思ったので、 Roo Code とやってみることにした。\n\n## 前提\n\n- Tier 4 の 3.7 Sonnet (thinking)\n- Cursor Pro を使うこともある\n\n## Architect is\n\nRoo Code には実行モードがデフォルトでいくつかあり、その内の一つ、 Cline だと「Plan」と呼ばれているもののはずで、コード生成をせずに設計を行うモード。\nいきなり実装に入るよりも、こっちで計画を立ててから実装に移るのがよいと言われている。\n\n同一コンテキストであればモードの切替でよいと思うが、今回は全体を書き直させたかったので一回じゃ足りないだろうなと思い、何かしらの記憶領域を使いたかった。\nこんな感じのフローで進めたい:\n\n1. Architect モードでどんなデザインにするかを相談する\n2. 話した内容をどこかにプランとして保存する\n3. 別の Code モードの Task で、プランを元に実装を進めて、進捗を記録する\n4. Content Window が足りなくなったら、それまでの実行結果を持って新しい Task に移動する\n\n先に言っておくと、意図せず Context Window が足りなくなるということが今回なかったので、各タスクは基本的にすべて完遂しているという前提で話が進む。\n\n## 保存と記録をどうするか\n\nCline 公式のドキュメントに Memory Bank というものがあって、これは現在のコードベースや進捗状況を書き出しておくことで、それを元に会話を進めることができるという考え方らしい。\n\n- https://docs.cline.bot/improving-your-prompting-skills/custom-instructions-library/cline-memory-bank\n\nそういうのがある、という知識としてはあったので、今回のリデザイン作業をする前にこの Memory Bank のプロンプトは動かしてみていたのだけど、個人的には微妙だなと感じていた。\nあくまで初学者の自分がそう感じているだけで、使い方が間違っているとか、使いこなせば便利なんだろうなという気はするが、次のような点が気になった:\n\n- activeContext が今回一番気になっていたが、更新されるタイミングがイマイチ掴めず\n- follow your custom instructions / update memory bank みたいなコマンド前提なのがちょっと面倒くさい\n- 多人数での利用に適したものなのか疑問、これは全く感覚が掴めなかったという話\n\nそんな感じだったのでこれを使うのはやめて(というか放置して)、もっとシンプルに `plan.md` と `state.md` というファイルを作ってみることにした。前者には Architect モードでの計画を吐き出してもらって、実装のたびに後者を更新していくようなイメージ。\nリデザインに限らず「Architect で相談 → Code で実装 → 状態を記録 → Code で実装 ...」という流れで何かしらを開発するとして、その一連の流れはリポジトリ全体で見ると一時的で個人的なイベントであるため、それを共有するような形にしても嬉しくないんじゃないかなというのもあった。\n\n## Architect で計画を立ててもらう\n\nGitHub のブログや CircleCI のブログがいい感じだなと思っていたので、スクリーンショットしてそれを参考にやってもらうことにした。\nCursor を使っているときもこの方法をよく使っていて、実装してもらいたい UI のスクリーンショットを取ってプロンプトに添付していた[^1]。\n\n[^1]: 添付という表現が合っているのかはわからない\n\n文字のプロンプトとしては以下で、これに画像が 2 つ付く感じ。\n\n```\n@/web/ を画像のようなデザインに変更したいので、どういう方針で進めていくかを考えてください\nまた、次の仕様を満たしてください:\n\n- ダークテーマとライトテーマの両方に対応\n- グレースケールを中心としつつも、赤をアクセントとして使っていく\n- ブログとノートはトップレベルでは混合させてもよい\n    - ただし、大きく表示してよいのはブログだけにする\n```\n\n<img src=\"/images/blog-redesign-with-architect-01.png\" alt=\"plan\">\n\nかなり雑な感じだけど、 Figma なりでデザインがあるわけでもなくなので、話しながら進められればいいかなくらいの感覚だった。\nそうするとこんな感じでいろいろ出してくれるので中身を確認する。\n\n<img src=\"/images/blog-redesign-with-architect-02.png\" alt=\"plan\">\n<img src=\"/images/blog-redesign-with-architect-03.png\" alt=\"plan\">\n<img src=\"/images/blog-redesign-with-architect-04.png\" alt=\"plan\">\n<img src=\"/images/blog-redesign-with-architect-05.png\" alt=\"plan\">\n\nなにかあったら言ってねと言われるので、計画を見て間違ってそうなところを直してもらう。\n\n```\n単体の記事を表示するヒーローセクションは不要で、4 つの記事を組み合わせるようなコンポーネントを作ってください。\n左には大きく最新のブログを 1 つ、右にはブログとノートの区別なく最新の 3 つを表示します。ただし、左と右でコンテンツに重複がないようにします。\n```\n\n<img src=\"/images/blog-redesign-with-architect-06.png\" alt=\"plan\">\n\n計画が更新されてくので、同じ手順とノリで満足するまで繰り返した。\nだいたい出来たあたりでこんな感じの質問があって、\n\n```\nRoo has a question:\n実装プランの詳細ありがとうございます。コンポーネント作成が必要とのことですが、まだAstroプロジェクトにcomponentsディレクトリがないようです。この部分について、どのように進めるべきでしょうか？また、デザインを実装する際の優先順位はどのように考えていますか？\n```\n\n```\ncomponents ディレクトリは作っても構いませんが、 astro contents を採用する予定がないので、それは使わないでください\n優先順位はなんでもいいのでお任せします\n```\n\nこう答えたら、実装を始めていいと勘違いしたのか Code モードに切り替えようとしたので一旦止めた。内容としてはこれくらいでよかったので、ついでに `plan.md` を作ってもらう。\n\n```\ncode モードに切り替える前に、ここまでの計画を plan.md にまとめて保存して\n```\n\nするとこんな感じに計画を作ってくれる、長すぎるので折り畳めるようにしたい。\n\n\n````\n# yaakai.to ウェブサイトリデザイン計画\n\n## 全体コンセプト\n\n- グレースケールをベースにした、赤色アクセントのモダンなデザイン\n- ブログとノートを視覚的に区別するレイアウト\n- ブログ記事を大きく表示し、ノートをコンパクトに表示\n- ダークモードとライトモード両対応\n- YouTubeチャンネルページのようなカテゴリ分けのある構造\n\n```mermaid\nflowchart TD\n    A[ヘッダー] --> B[メタコンテンツセクション]\n    B --> B1[humans.txt]\n    B --> B2[rss.xml]\n    B --> B3[llms.txt]\n    B --> C[フィーチャーセクション]\n    C --> C1[左大型カード - 最新ブログ]\n    C --> C2[右サイド - 最新3記事]\n    C --> D[カテゴリセクション]\n    D --> D1[ブログセクション]\n    D1 --> D1a[グリッドレイアウト]\n    D --> D2[ノートセクション]\n    D2 --> D2a[グリッドレイアウト]\n```\n\n## カラースキーム\n\n```css\n:root {\n  /* グレースケールパレット - ライトモード */\n  --gray-100: #FFFFFF;\n  --gray-200: #F9F9F9;\n  --gray-300: #F0F0F0;\n  --gray-400: #E0E0E0;\n  --gray-500: #C0C0C0;\n  --gray-600: #808080;\n  --gray-700: #505050;\n  --gray-800: #303030;\n  --gray-900: #121212;\n\n  /* アクセントカラー - 赤色系 */\n  --red-500: #E53935;\n  --red-600: #D32F2F;\n  --red-700: #C62828;\n\n  /* 機能的な色の割り当て */\n  --bg-color-level-0: var(--gray-100);\n  --bg-color-level-1: var(--gray-200);\n  --bg-color-level-2: var(--gray-300);\n  --bg-color-level-3: var(--gray-400);\n  --bg-color-level-4: var(--gray-500);\n\n  --text-color-level-0: var(--gray-900);\n  --text-color-level-1: var(--gray-800);\n  --text-color-level-2: var(--gray-700);\n\n  --primary-color-level-0: var(--red-600);\n  --primary-color-level-1: var(--red-500);\n  --primary-color-level-2: var(--red-700);\n\n  /* コンテンツタイプ識別色 */\n  --blog-color: var(--red-600);\n  --note-color: var(--gray-600);\n}\n\n@media (prefers-color-scheme: dark) {\n  :root {\n    /* ダークモード用の色の割り当て */\n    --bg-color-level-0: #121212;\n    --bg-color-level-1: #1E1E1E;\n    --bg-color-level-2: #2D2D2D;\n    --bg-color-level-3: #353535;\n    --bg-color-level-4: #424242;\n\n    --text-color-level-0: #FFFFFF;\n    --text-color-level-1: #E0E0E0;\n    --text-color-level-2: #BDBDBD;\n\n    --primary-color-level-0: #F44336;\n    --primary-color-level-1: #EF5350;\n    --primary-color-level-2: #E53935;\n\n    /* ダークモードでのコンテンツタイプ識別色 */\n    --blog-color: #FF5252;\n    --note-color: #A0A0A0;\n  }\n}\n```\n\n## コンポーネント設計\n\n### 1. ヘッダー\n- シンプルなナビゲーション\n- サイト名とアイコン\n- ブログとノートへのリンク\n\n### 2. メタコンテンツセクション\n- humans.txt セクションの表示（現在と同様の表示スタイル）\n- humans.md の内容を表示\n- rss.xml へのリンクを追加\n- llms.txt へのリンクを追加\n- メタコンテンツへのリンクを視覚的にまとめて配置\n\n### 3. フィーチャーセクション\n- 非対称グリッドレイアウト\n- 左側に大きなカード（最新ブログ記事）\n- 右側に3つの小さなカード（最新記事）\n- グリッドベースで水平スクロールなし\n\n```css\n.feature-section {\n  display: grid;\n  grid-template-columns: 3fr 2fr;\n  gap: 24px;\n  margin-bottom: 48px;\n}\n\n.feature-main {\n  grid-column: 1;\n  grid-row: span 3;\n}\n\n.feature-sub {\n  grid-column: 2;\n  display: flex;\n  flex-direction: column;\n  gap: 16px;\n}\n```\n\n### 4. カテゴリセクション\n- 各カテゴリごとのセクション（ブログ、ノートなど）\n- カテゴリ名と「もっと見る」リンクを含むヘッダー\n- レスポンシブグリッドレイアウト\n- コンテンツタイプの視覚的区別\n\n```css\n.category-section {\n  margin-bottom: 48px;\n}\n\n.category-header {\n  display: flex;\n  justify-content: space-between;\n  align-items: center;\n  margin-bottom: 24px;\n}\n\n.category-grid {\n  display: grid;\n  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));\n  gap: 24px;\n}\n```\n\n### 5. カードデザイン\n\n#### ブログカード\n- 大きな画像/サムネイル\n- 赤色アクセントのインジケーター\n- タイトル、日付、概要テキスト\n\n#### ノートカード\n- コンパクトなデザイン\n- グレースケールベース\n- 絵文字とタイトルを主体に\n\n## レスポンシブデザイン\n\n### デスクトップ (1024px以上)\n- フィーチャーセクション：非対称グリッド (3:2)\n- カテゴリグリッド：4列\n\n### タブレット (768px - 1023px)\n- フィーチャーセクション：非対称グリッド (3:2)\n- カテゴリグリッド：2-3列\n\n### モバイル (768px未満)\n- フィーチャーセクション：1列\n- カテゴリグリッド：1列\n\n# 実装プラン\n\n## コンポーネント構造について\n\nAstro Contentsは使わず、コンポーネントは以下のように実装します：\n\n1. **src/components ディレクトリを新規作成**：\n   - 再利用可能なUI要素をコンポーネントとして実装\n   - 各コンポーネントは独立した.astroファイルとして作成\n\n2. **コンポーネント名の例**：\n   - `BlogCard.astro`\n   - `NoteCard.astro`\n   - `FeatureGrid.astro`\n   - `CategorySection.astro`\n\n## ディレクトリ構造\n\n```\nsrc/\n├── components/     <- 新規作成\n│   ├── BlogCard.astro\n│   ├── NoteCard.astro\n│   ├── FeatureGrid.astro\n│   └── CategorySection.astro\n├── layouts/        <- 既存\n│   ├── global-layout.astro\n│   └── blog-post.astro\n└── pages/          <- 既存\n    ├── index.astro\n    ├── blog/\n    └── note/\n```\n\n## 実装の優先順位\n\n1. **グローバルスタイルの更新**\n   - カラースキームの変更\n   - 基本レイアウト構造の改善\n   - タイポグラフィの更新\n\n2. **コアコンポーネントの作成**\n   - カードデザイン\n   - グリッドレイアウト\n   - セクションヘッダー\n\n3. **トップページの再構築**\n   - フィーチャーグリッド\n   - カテゴリセクション\n   - レスポンシブデザイン対応\n\n4. **各ページの更新**\n   - ブログインデックスページ\n   - ノートインデックスページ\n   - 記事詳細ページ\n\n## 詳細実装ステップ\n\n### フェーズ1: グローバルスタイルとレイアウトの更新\n\n#### 1-1. カラースキームの更新\n```mermaid\nflowchart TD\n    A[web/src/layouts/global-layout.astro] --> B[CSSカラー変数の更新]\n    B --> C[ライト/ダークモードの調整]\n```\n\n**作業内容:**\n- `web/src/layouts/global-layout.astro` ファイルの CSS 変数を更新\n- グレースケールベースのカラーパレットを実装\n- 赤色アクセントカラーの設定\n- ブログとノートの識別色の設定\n\n#### 1-2. 基本レイアウトの更新\n```mermaid\nflowchart TD\n    A[web/src/layouts/global-layout.astro] --> B[コンテナ構造の更新]\n    B --> C[ヘッダースタイルの改善]\n```\n\n**作業内容:**\n- ページ全体のコンテナサイズと余白の調整\n- ヘッダーのデザイン更新\n- 基本的なグリッドレイアウトの準備\n\n### フェーズ2: コンポーネントの作成\n\n#### 2-1. カードコンポーネントの作成\n```mermaid\nflowchart TD\n    A[src/components/] --> B[BlogCard.astro]\n    A --> C[NoteCard.astro]\n    A --> D[FeatureCard.astro]\n```\n\n**作業内容:**\n- `src/components/` ディレクトリを作成\n- ブログ用カードコンポーネントの実装\n- ノート用カードコンポーネントの実装\n- フィーチャーセクション用の大型カードコンポーネントの実装\n\n#### 2-2. セクションコンポーネントの作成\n```mermaid\nflowchart TD\n    A[src/components/] --> B[FeatureGrid.astro]\n    A --> C[CategorySection.astro]\n```\n\n**作業内容:**\n- フィーチャーグリッドコンポーネントの実装\n- カテゴリセクションコンポーネントの実装\n- 各セクションのレスポンシブデザイン対応\n\n### フェーズ3: トップページの再構築\n\n#### 3-1. メタコンテンツセクションの更新\n```mermaid\nflowchart TD\n    A[web/src/pages/index.astro] --> B[メタコンテンツの表示スタイル更新]\n    B --> C[各リンクの配置とスタイル]\n```\n\n**作業内容:**\n- humans.txt セクションのスタイルを更新\n- rss.xml と llms.txt へのリンクを追加\n- メタコンテンツをグループとして視覚的にまとめる\n- 新しいデザインテーマに合わせたスタイル調整\n\n#### 3-2. フィーチャーセクションの実装\n```mermaid\nflowchart TD\n    A[web/src/pages/index.astro] --> B[データ取得ロジックの更新]\n    B --> C[FeatureGridコンポーネントを使用]\n```\n\n**作業内容:**\n- ブログとノートの記事データ取得ロジックの改善\n- 最新記事を取得して、左側に最新ブログ、右側に残りの最新記事を配置\n- フィーチャーグリッドコンポーネントを使用して表示\n\n#### 3-3. カテゴリセクションの実装\n```mermaid\nflowchart TD\n    A[web/src/pages/index.astro] --> B[ブログセクションの実装]\n    A --> C[ノートセクションの実装]\n```\n\n**作業内容:**\n- ブログ記事用のカテゴリセクション実装\n- ノート用のカテゴリセクション実装\n- CategorySectionコンポーネントを使用して表示\n\n### フェーズ4: 各ページの更新\n\n#### 4-1. ブログページの更新\n```mermaid\nflowchart TD\n    A[web/src/pages/blog/index.astro] --> B[グリッドレイアウトの更新]\n    B --> C[BlogCardコンポーネントの使用]\n```\n\n**作業内容:**\n- ブログインデックスページのレイアウト更新\n- カテゴリフィルターの追加（将来機能）\n- BlogCardコンポーネントを使用した記事表示\n\n#### 4-2. ノートページの更新\n```mermaid\nflowchart TD\n    A[web/src/pages/note/index.astro] --> B[グリッドレイアウトの更新]\n    B --> C[NoteCardコンポーネントの使用]\n```\n\n**作業内容:**\n- ノートインデックスページのレイアウト更新\n- NoteCardコンポーネントを使用した記事表示\n\n### フェーズ5: 詳細ページとレスポンシブ対応\n\n#### 5-1. 記事詳細ページの更新\n```mermaid\nflowchart TD\n    A[web/src/layouts/blog-post.astro] --> B[詳細ページのスタイル更新]\n    B --> C[関連記事セクションのデザイン改善]\n```\n\n**作業内容:**\n- 記事詳細ページのレイアウト更新\n- Markdownスタイルの調整\n- 関連記事セクションのデザイン改善\n\n#### 5-2. レスポンシブデザインの最適化\n```mermaid\nflowchart TD\n    A[すべてのコンポーネント] --> B[モバイル対応の強化]\n    B --> C[タブレット対応の調整]\n    C --> D[大画面対応の最適化]\n```\n\n**作業内容:**\n- すべてのコンポーネントとページでのレスポンシブデザイン強化\n- モバイルファーストでのスタイル調整\n- メディアクエリの統一と最適化\n\n## 実装の注意点\n\n1. **段階的アプローチ**：一度にすべてを変更するのではなく、段階的に実装して各フェーズで確認する\n\n2. **コンポーネント分離**：再利用可能なコンポーネントを作成し、コードの重複を避ける\n\n3. **型の活用**：TypeScriptの型を適切に利用し、データの整合性を確保する\n\n4. **パフォーマンス考慮**：画像最適化やCSSの効率的な構造化を考慮する\n\n5. **アクセシビリティ対応**：対比の確保、キーボード操作、スクリーンリーダーのサポートなど\n\n6. **テスト**：各フェーズで異なるデバイスサイズやブラウザでのテストを実施\n\n````\n\n内容が合っているかを確認する、多分いい感じ。 `plan.md` も作ってもらう。\n\n```\nタスクが完了するごとに、plan.md をどこまで進めたかを state.md として書き出すようにして\n```\n\n````\n**最終更新**: 2025年3月4日\n\n## 概要\nyaakai.toウェブサイトをモダンなグレースケールベース + 赤色アクセントのデザインに更新するプロジェクト。ブログとノートを視覚的に区別するレイアウトを実装し、YouTubeチャンネルページのようなカテゴリ分けを導入します。\n\n## 現在の進捗状況\n\n### フェーズ1: グローバルスタイルとレイアウトの更新\n- [ ] 1-1. カラースキームの更新\n- [ ] 1-2. 基本レイアウトの更新\n\n### フェーズ2: コンポーネントの作成\n- [ ] 2-1. カードコンポーネントの作成\n- [ ] BlogCard.astro\n- [ ] NoteCard.astro\n- [ ] FeatureCard.astro\n- [ ] 2-2. セクションコンポーネントの作成\n- [ ] FeatureGrid.astro\n- [ ] CategorySection.astro\n\n### フェーズ3: トップページの再構築\n- [ ] 3-1. メタコンテンツセクションの更新\n- [ ] 3-2. フィーチャーセクションの実装\n- [ ] 3-3. カテゴリセクションの実装\n\n### フェーズ4: 各ページの更新\n- [ ] 4-1. ブログページの更新\n- [ ] 4-2. ノートページの更新\n\n### フェーズ5: 詳細ページとレスポンシブ対応\n- [ ] 5-1. 記事詳細ページの更新\n- [ ] 5-2. レスポンシブデザインの最適化\n\n## 次のステップ\n1. グローバルレイアウトのカラースキームを更新\n2. 基本レイアウト構造の改善\n3. コンポーネントディレクトリを作成し、初期コンポーネントを実装\n\n## 備考\n- 計画は [plan.md](./plan.md) に詳細に記述されています\n- デザインはグレースケールベースに赤色アクセントを組み合わせたモダンなスタイル\n- ブログとノートは視覚的に区別されるデザインを採用\n- メタコンテンツ（humans.txt、rss.xml、llms.txt）はトップレベルでグループ化\n````\n\nそれっぽいのが出てきた。そして実装に移ろうとするので、待てして Task を引き継ぐためのプロンプトを考えてもらう。\n\n<img src=\"/images/blog-redesign-with-architect-07.png\" alt=\"plan\">\n\n\n## 実装してもらう\n\n教えてもらったプロンプトを少し変更してして、`@` でファイルを読むようにした。\n\n```\n@/web/plan.md  に記載された計画に従って、yaakai.toウェブサイトのリデザイン実装を進めてください。まずは @/web/src/layouts/global-layout.astro のカラースキーム更新から始め、計画の各フェーズを順番に実装していってください。各ステップが完了するたびに @/web/state.md を更新して進捗を記録してください。最初に計画と現在の進捗状況を確認して、実装を開始してください。\n```\n\nプロンプトに `plan.md` がちゃんと含まれている図:\n\n<img src=\"/images/blog-redesign-with-architect-08.png\" alt=\"plan\">\n\n確認できたみたいで、計画されていたカラースキームの変更から実装が始まっていく：\n\n<img src=\"/images/blog-redesign-with-architect-09.png\" alt=\"plan\">\n\n\nすべては貼れないので一部を抜粋すると、計画された順に実装を進めていこうとしていることがわかる:\n\n<img src=\"/images/blog-redesign-with-architect-10.png\" alt=\"plan\">\n\nただ、 `state.md` はというと↑の画像くらいのタイミングで進捗を更新してほしかったが、今回のプロンプトだとそれは叶わなかった。\nこんな感じに最後にまとめてこの Task でやった分を更新してくれた:\n\n<img src=\"/images/blog-redesign-with-architect-11.png\" alt=\"plan\">\n<img src=\"/images/blog-redesign-with-architect-12.png\" alt=\"plan\">\n\nContext Window が足りている分にはこれでも構わないが、自分はそれが途切れたときに `state.md` からある程度状態を復元できることを期待していたので、もっとフェーズを進めるごとにガンガン書き込んでほしかった。\nWeb の情報を見ていると、そういう動きをしているものもあるように思うので、これはまたあとに試す予定。\n\nあとは同じような手順で、新しい Task を作るときは `plan.md` と `state.md` を読み込み更新しながら実装を進めていった。\n実際どの程度の効果があったかを説明するのは難しいが...、以前にやったときは「今お前が壊したそれ、この前お前が直したじゃん」みたいなことがあったけど、そういう手戻りみたいなことはなかったように思う。\n\n## CSS をうまく書けないので覚えてもらう\n\nそういう話題に関連することとして、ミクロな話だと少し複雑な CSS を頑張って実装しても次の瞬間には忘れて破壊する、というのがあった。\n具体的にはアイキャッチを 2 つのコンテナを跨いでいるように見せるという実装。\n\n<img src=\"/images/blog-redesign-with-architect-13.png\" alt=\"plan\">\n\n\nこれをなんとかして伝えようとしているのだけどまぁうまくいかない。で、最終的にはこれは自分が手で実装することにした。そこまではよいのだけど、問題は次にその周辺を触ったときに、必ずその実装が破壊されて Task が完了するごとに戻っていた。\nこれを解決しないと先に進めないので、実装方針を説明して `plan.md` や `state.md` に書いてもらう、というのを試した。\n\n```\nアイキャッチが記事本文側の要素に少しずれているような視覚効果を実現します。\nあなたはいままでこれの実装を何度も失敗しているので、私がいう実装方法を覚えてください。\n\n1. .article-header の bottom の padding や margin  を削除して、アイキャッチの下が .article-header の終端と合うようにします\n2. .eyecatch-container の兄弟として新たな要素を挿入します、これは記事側と同じ背景色を持ちます\n3. この要素を z-index で .eyecatch-container より下にした状態で、 position: absolute; で高さ 80px を持ちつつ、.article-header の終端に合うよう固定します\n```\n\nなるべく頑張って実装を説明した、これを入れたのはぶっ壊れたあとなので、 AI が自身でこの実装を修正する必要があった。\nこの指示はかなりうまくいって、過去に実装された事実があるとはいえ、望んでいたものが改めて AI によって実装された。\n\n<img src=\"/images/blog-redesign-with-architect-14.png\" alt=\"plan\">\n\n\nその後 `plan.md` や `state.md` を更新してもらうと、それらを含めている限りはここに関する手戻りは発生していないように思えた。えらい。\n\n\n## 雑感\n\n### 計画を吐き出すのは良さそう\n\n`plan.md` は結構いいように思えたので使っていきたい。 `state.md` はどのくらい効果があったのか肌感がない、わざわざ分ける必要はないかも。\n\n### 個人用のメモスペースがほしい\n\n`plan.md` なんかを自由に作れるスペースがリポジトリ内にほしい。AI との会話の成果物を一時的に保存する場所が gitignore されてリポジトリに確保されているといいなと思った、今回は commit してしまったが...。\n先にも書いたが、全体で共有したいルールがある一方で、個人が一つの作業で使う一時記憶ファイルを全部 commit したいとはならなさそう。そのファイル自体もバージョン管理したいという気持ちもあるので、 submodule なのか...？\n\n### 複雑なコードは個別の取説を置きたい\n\nマスターデータとなるデザインデータなんかが存在しない中では仕方ないことなのかもしれないが、 HTML + CSS な UI 構築に関しては自分が手を出さないといけないことが多い気がしている、もちろん詳細なデザインは妥協しているが。\n今回のような内容をすべてプロンプトに含めるわけにもいかないので、コンポーネントのような単位でその実装を説明した 取説.md を横においておき、コンポーネントを触るときはその取説を参照させるような仕組みが出来るといいのかもしれない。\nと思っていたけど、大抵はコメントとして残しておけば解決する話なのかもしれない。",
    "createdAt": "2025-03-05T00:00:00.000Z",
    "updatedAt": "2025-03-05T00:00:00.000Z",
    "publishedAt": "2025-03-05T00:00:00.000Z",
    "tags": [],
    "path": "/blog/blog-redesign-with-architect"
  },
  {
    "id": "rule-files-unified-management",
    "title": "Project Rules や .clinerules や CLAUDE.md をまとめて管理する",
    "content": "これを書いている 2025 年 3 月 24 日時点では、いわゆる rules ファイルを作って AI Coding の性能を向上させようという共通認識はあるものの、各種ツールでそのフォーマットは統一されていない。\nそのため現状では、複数のツールを使っていたり、人によってツールが異なるチームだと何かしらの方法でこれらを一元管理する必要があり、これは自分が今やっている方法を書き残したもの。\n\n## 現状\n\n### Cursor / Project Rules\n\n`.cursorrules` というファイルを使っていたが非推奨になり、 Project Rules という独自形式に移行した。\n\n- https://docs.cursor.com/context/rules-for-ai#project-rules-recommended\n\nここで使われる `.mdc` 形式は Front Matter でルールを適用する範囲を glob で定義できる:\n\n```\n---\ndescription: frontend の開発ルール（常に参照）\nglobs: packages/frontend/**/*\nalwaysApply: true\n---\n```\n\n性質が異なるので一元的に評価することは難しいが、Cursor の操作感と相まって他より 1 歩進んでいるという印象。\n\n### Cline / .clinerules\n\n`.clinerules` というファイルを使っていたが、直近で `.clinerules` がディレクトリに出来るようになった。\n\n- https://docs.cline.bot/improving-your-prompting-skills/prompting#clinerules-folder-system\n\nCursor の mdc のように glob 機能があるわけではなく、単純に `.clinerules` ディレクトリにあるファイルがすべて適用される。\nコンテキストに含めるものの変更はファイルの移動が伴うため、公式に次のような運用が推奨されており、今回もこれを参考にしている:\n\n- `clinerules-bank` のような非アクティブなルールを格納しておくディレクトリを作る\n- 複数人で運用する場合は `.clinerules` は gitignore に入れておき、各自が必要なものを移動させて利用する\n- コンテキストの切り替えをスムーズにするためのスクリプトを用意する\n\n#### Roo Code\n\n- https://docs.roocode.com/advanced-usage/custom-instructions/\n\nCline のフォークだが、少し特殊で `.clinerules` `.cursorrules` `.windsurfrules` の 3 つを読み込んでくれる。\n\n- https://github.com/RooVetGit/Roo-Code/blob/main/src/core/prompts/sections/custom-instructions.ts#L20\n\n### Claude Code / CLAUDE.md\n\n- https://docs.anthropic.com/ja/docs/agents-and-tools/claude-code/tutorials#claude-md\n\nCursor や Cline のディレクトリ化以前のシンプルなファイルと本質的には変わらないが、 `claude` を実行したディレクトリのものが適用されるという特性がある。\n当たり前といえばそうなのだが、これを Monorepo の場合で考えると、作業をする際にそのパッケージのディレクトリで `claude` を実行することでコンテキストを切り替えることができる。\n今回はこの特性を基準として rules の構成を考えている。\n\nCLAUDE.md を Claude Code に作らせたときに面白かったことして、 claude code 自身の解説による `/init` がこのファイルは 20 行程度に作るべきだと定義しているっぽく、他のツールと比べて明らかに内容が少なくなる、というのがあった。\n自分はどちらかと言えばこれに賛成というか、(将来的には)長い知識を書き連ねるよりは、最小限にして毎度コンテキストを作ればいいよと思っている。\n\n### Copilot / .github/copilot-instructions.md\n\n- https://docs.github.com/ja/copilot/customizing-copilot/adding-repository-custom-instructions-for-github-copilot\n\nCursor を使っていて、兼用はしていないので作っていない。\n\n\n### Windsurf / .windsurfrules\n\n- https://docs.codeium.com/windsurf/memories#windsurfrules\n\nこれに関しては自分は Windsurf は使っていないのでそれに関する言及はないが、他とコンフリクトしないので Roo Code 用に作成している。\n\n## どう管理するか\n\n現状を踏まえて次のようにやっている:\n\n- rules ディレクトリを作り、その中に Monorepo のパッケージ構造と同じになるようルールを分割して配置する\n- Cursor と claude はコンテキストに合わせたファイルをそれぞれ作成する\n- Cline と `.windsurfrules` はコンテキストを指定してファイルを配置したり結合する\n\n前述した通り、現状では CLAUDE.md を Monorepo の各パッケージに配置することで実質的にコンテキストを切り替えることができる、というのを基準に考えている。\nコンテキストの切り替えを考える基準としては、ビジネス基準で考えるか技術基準で考えるかがあると思うが、 Monorepo 内で分けられたパッケージ単位でコンテキストが異なるレベルの技術が混在することは少ないだろうと考えて、ビジネス基準で分けている。\nSingle Repo (= リポジトリに一つのコンテキスト)の場合は単にファイルを分割して結合なりすればよいだけなので割愛するが、サブディレクトリが省略されるだけで同じものを使っている。\n\n### Monorepo の構造\n\n自分が情報収集のために作っているアプリを例に出す。これはざっくりいうと以下の 4 つ(の種類)のパッケージがあり、それぞれでコンテキストを切り替えて開発したい。\n\n- RSS 収集し、 AI を使ってフィルタリングや要約を行うパッケージ\n- 上で作られたデータや他の RSS を収集し、デイリーの単位でまとめを行うバックエンドアプリ\n- それを読むための Chrome 拡張\n- ユーティリティライブラリ\n\n```\npackages\n├── claude-3\n├── core\n├── openai\n├── reader-backend\n├── reader-chrome-extension\n├── rss-blog-release-notes\n├── rss-books\n├── rss-github-changelogs\n├── rss-hatena-bookmark\n├── rss-oss-release-notes\n├── ...\n├── rss-personal-blogs\n├── rss-tech-blogs-en\n├── rss-tech-blogs-jp\n├── source-utils\n├── string-utils\n└── xml-utils\n```\n\n### rules の構造\n\nこれに合わせて次のように rules を分割して配置している。\n\n```\n/\n├── packages\n└── rules\n    ├── reader-backend\n    │   ├── 01-init.md\n    │   ├── 02-workflow.md\n    │   └── 03-architecture.md\n    ├── reader-chrome-extension\n    │   ├── 01-init.md\n    │   ├── 02-workflow.md\n    │   ├── 03-architecture.md\n    │   └── 06-patterns.md\n    ├── rss-\n    │   ├── 01-init.md\n    │   ├── 02-workflow.md\n    │   ├── 03-architecture.md\n    │   └── 06-patterns.md\n    ├── 01-init.md\n    ├── 02-workflow.md\n    ├── 03-architecture.md\n    ├── 04-coding.md\n    ├── 05-testing.md\n    ├── 06-patterns.md\n    └── generate-ai-rules.js\n```\n\nそれぞれのファイルには名前に対応した内容を書いているが、 rules 直下のものにはより広い範囲の事柄を、それぞれのものには狭い範囲の事柄を書いている。\n例えば `rules/03-architecture.md` には Monorepo 全体の構造を書いて、 `rules/reader-backend/03-architecture.md` にはバックエンドアプリの設計方針が書いてある感じ。\n\n工夫として、 `01-init.md` には次のように書いている:\n\n```\n最初に「reader-backend のコンテキストで処理しています。」と発言してください。\n```\n\nこうしておくことで、今読み込まれているものを認知できるようにしている。注意点として Cursor で 2 つのコンテキストをまたぐとうまく発言しないが、読み込み自体はうまく行っているはず。\n\nまた、ディレクトリ名が `-` で終わる場合は前方一致で対象のディレクトリを判定している。今回の場合は `rss-` で始まるパッケージには `rss-` 以下のルールがすべて適用される。\n\n### スクリプトで連結して配置する\n\n`rules/generate-ai-rules.js` を実行するとそれぞれに対応するファイルが一括で出力されるようになっている:\n\n```\n$ ./rules/generate-ai-rules.js\n```\n\nこのスクリプトは引数を取ることが出来て、 `.clinerules` と `.windsurfrules` はこの引数によって内容が変化する:\n\n```\n$ ./rules/generate-ai-rules.js reader-backend\n$ ./rules/generate-ai-rules.js rss-\n```\n\nこれを例えば `reader-backend` を引数に実行するとこのようにファイルが配置される:\n\n```\n├── .clinerules\n│   ├── reader-backend\n│   │   ├── 01-init.md\n│   │   ├── 02-workflow.md\n│   │   └── 03-architecture.md\n│   ├── 01-init.md\n│   ├── 02-workflow.md\n│   ├── 03-architecture.md\n│   ├── 04-coding.md\n│   ├── 05-testing.md\n│   └── 06-patterns.md\n├── .cursor\n│   └── rules\n│       ├── reader-backend.mdc\n│       ├── reader-chrome-extension.mdc\n│       ├── rss-.mdc\n│       └── rules.mdc\n├── packages\n│   ├── reader-backend\n│   │   └── CLAUDE.md\n│   ├── reader-chrome-extension\n│   │   └── CLAUDE.md\n│   ├── rss-blog-release-notes\n│   │   └── CLAUDE.md\n│   ├── rss-books\n│   │   └── CLAUDE.md\n│   ├── rss-github-changelogs\n│   │   └── CLAUDE.md\n│   ...\n├── CLAUDE.md\n└── .windsurfrules\n```\n\nあまり汎用的なスクリプトという感じでもないし、この状況が長く続くとは思えないので破棄のしやすさも兼ねて、それぞれのリポジトリに合うものを作っている。\n\nわかりやすいものから順に内容を解説する。\n\n### .clinerules\n\nCline は `rules` 直下のものと、コマンドの引数で指定されたものを `.clinerules` ディレクトリに配置する。\nコンテキストを変えたいときは、スクリプトを実行して配置されているファイルを切り替える。\n\n### .windsurfrules\n\n`.clinerules` と同じようにコマンドの引数でコンテキストが変わるが、ディレクトリには対応していないため 1 ファイルに内容をまとめる必要がある。\n例えば rss- パッケージの場合は次のような順でファイルを連結したものを `.windsurfrules` としている:\n\n```\nrules/01-init.md\nrules/rss-/01-init.md\nrules/02-workflow.md\nrules/rss-/02-workflow.md\nrules/03-architecture.md\nrules/rss-/03-architecture.md\nrules/04-coding.md\nrules/05-testing.md\nrules/06-patterns.md\nrules/rss-/06-patterns.md\n```\n\n### .cursor/rules\n\n`rules` 直下のものはすべてを対象に、サブディレクトリ配下のものは対応するパッケージを対象に glob を設定して連結している。\n例えば rss- パッケージ向けのものはこのようになっている:\n\n```\n---\ndescription: rss- パッケージのルール（常に参照）\nglobs: packages/rss-*/**/*\nalwaysApply: true\n---\n\n最初に「rss- のコンテキストで処理しています。」と発言してください。\n\n...\n```\n\nそれぞれのファイルは次のように連結している:\n\n```\n.cursor/rules/rules.mdc\n  - rules/01-init.md\n  - rules/02-workflow.md\n  - rules/03-architecture.md\n  - rules/04-coding.md\n  - rules/05-testing.md\n  - rules/06-patterns.md\n.cursor/rules/reader-backend.mdc\n  - rules/reader-backend/01-init.md\n  - rules/reader-backend/02-workflow.md\n  - rules/reader-backend/03-architecture.md\n.cursor/rules/reader-chrome-extension.mdc\n  - rules/reader-chrome-extension/01-init.md\n  - rules/reader-chrome-extension/02-workflow.md\n  - rules/reader-chrome-extension/03-architecture.md\n  - rules/reader-chrome-extension/06-patterns.md\n.cursor/rules/rss-.mdc\n  - rules/rss-/01-init.md\n  - rules/rss-/02-workflow.md\n  - rules/rss-/03-architecture.md\n  - rules/rss-/06-patterns.md\n```\n\nこれに似たアプローチは他の方も試されていてそちらも参考になる：\n\n- https://zenn.dev/ks0318/articles/b8eb2c9396f9cb\n\n\n### CLAUDE.md\n\nそれぞれのパッケージに、 `.windsurfrules` として生成するものと同等のものを配置している。事前にすべて作っておけるイメージ。\n例えば `packages/reader-backend/CLAUDE.md` の内容は `$ ./rules/generate-ai-rules.js reader-backend` を実行したときに生成される `.windsurfrules` と同じものになる。\n\nコンテキストの切り替えはディレクトリ移動して `claude` を実行することで行う:\n\n```\n$ cd packages/reader-backend\n$ claude\n```\n\n## その他\n\nどのくらい効果があるかは分からないが 、Claude Code の CLI モードでプロンプトを評価させている。\n\n```json\n{\n  \"scripts\": {\n    \"rules:lint\": \"rm -rf .cursor .clinerules CLAUDE.md .windsurfrules && claude -p \\\"あなたはリンターです。rules以下のmdファイルがあなたや他のAIコーディングツールに渡す情報として適切かをコードベースと照らし合わせてよく考えて回答してください。\\\"\"\n  }\n}\n```\n\n全くそうではないのに「このリポジトリは DDD でクリーンアーキテクチャです」みたいなことを書くとちゃんと怒ってくれるので、初期段階ではそれなりに効果があると思う。\n実行する前に関連ファイルを消しておかないと、連結済みのものを読んだ状態になるので注意。",
    "createdAt": "2025-03-24T00:00:00.000Z",
    "updatedAt": "2025-03-24T00:00:00.000Z",
    "publishedAt": "2025-03-24T00:00:00.000Z",
    "tags": [],
    "path": "/blog/rule-files-unified-management"
  },
  {
    "id": "develop-in-codespaces-and-devcontainer",
    "title": "個人開発を Codespaces と DevContainer へ移行",
    "content": "[Codespaces](https://github.com/features/codespaces) が利用できるようになってから、ちょっとした開発は Codespaces を行っていたのですが、最近は個人の開発はすべて Codespaces で十分だと思えてきたので完全に移行しようと思いました。\nただ、基本的には無料枠でやっているので[^1]、ある程度腰を据えて開発していると枠が足りなくなるのと、Chrome 拡張の開発は毎回成果物のダウンロードが必要だったりで不便なところは少しあるので、それを埋めるために一部で [Dev Container](https://code.visualstudio.com/docs/devcontainers/containers) を使って、手元のマシン内で開発可能な環境を整えることにしました。\n\n[^1]: 追加することに抵抗があるわけではないので、理由がなければ Codespaces を継続してます。\n\nこれは、その準備をしたときの作業ログと未来の自分に向けたメモです。ある程度 Codespaces を触ったことがあるという前提で書かれています。\n\n## 開発用コンテナと Dockfile について\n\nCodespaces と Dev Container で使用するコンテナに関する設定を区別する必要なく、同じものが使えます。\nDocker Desktop に相当するものがインストールされていれば、VSCode に Dev Containers のプラグインを入れればそのまま利用可能です。\n\n- https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers\n\nローカルで開発するときはコードを適当な場所に clone して「Open in container」から開きます。コマンドパレットからも開き直せます、その場合は Reopen ~ になります。\n\n### Clone Repository in Container\n\nコードの clone をコンテナの中で行うという方法もあるようです。これを利用すると Codespace とほとんど同じ感覚で使えるようです。\n\n- [【vscode】devcontainerのClone in container volumeがよいという話](https://weseek.co.jp/tech/4112/)\n- [Create a development container using Visual Studio Code Remote Development](https://code.visualstudio.com/docs/devcontainers/create-dev-container#_add-an-open-in-dev-container-badge)\n\nただ、何回試してみたのですが、shallow clone になってしまってだるいのと、成果物がコンテナ内に入ってしまうので取り出すのがめんどくさい、という理由があって使っていません。\n\n### OrbStack\n\n個人の MBA では Docker Desktop の代わりに [OrbStack](https://orbstack.dev/) を試しています。\n\n- [OrbStack · Fast, light, simple Docker & Linux on macOS](https://orbstack.dev/)\n- [OrbStack使ってみた](https://zenn.dev/daifukuninja/articles/6285b5491a05e5)\n\nいまのところ特に問題なく Docker Desktop の代わりとして使えています。\n\n## Dotfiles について\n\nここ数年は fish を使っていたのですが、devcontainers のものにはデフォルトでは入っていないので、これを機に zsh に戻してみることにしました。\nこれまで Codespaces を使うときは不便を感じつつも特にカスタマイズをしていなかったので、今回ちゃんと設定を整えてみることにしました。\n\n- [yaakaito/env](https://github.com/yaakaito/env)\n\n開発に使う devcontainer をある程度テンプレ化しておきたかったので[^2] dotfiles ではなくて env という名前にしてみました。\n\n[^2]: テンプレートリポジトリはリポジトリが増えるし同じようなことをそれぞれに更新かけたりがだるいので。\n\nCodepsaces の場合は、GitHub の設定から dotfiles のリポジトリを指定することで、Codespaces が起動するときに dotfiles の内容がコンテナにコピーされ、setup.sh が実行されます。\n\n- [アカウントの GitHub Codespaces をパーソナライズする - GitHub Docs](https://docs.github.com/ja/codespaces/customizing-your-codespace/personalizing-github-codespaces-for-your-account#turning-on-settings-sync-in-a-codespace)\n\nDev Container の場合は、VSCode の設定から GitHub にある dotfiles のリポジトリを指定ことができます。これをすると Codespaces と同等の挙動になります。\n\n```json\n{\n  \"dotfiles.repository\": \"yaakaito/env\",\n  \"dotfiles.targetPath\": \"~/.env\",\n}\n```\n\n### zsh のカスタマイズ\n\nとはいえ欲しい物が fish っぽく動いてほしいくらいだったので、次の記事を参考に [zsh-autosuggestions](https://github.com/zsh-users/zsh-autosuggestions) と [zsh-syntaxhighlight](https://github.com/zsh-users/zsh-syntax-highlighting/) を入れて、fish ライクに、peco で ctrl-r に履歴検索、ctrl-s でディレクトリ移動をバインドしています。\n\n- [Setup guide for ZSH in GitHub codespaces - DEV Community](https://dev.to/krish_agarwal/setup-guide-for-zsh-in-github-codespaces-5152)\n- [ghqでリポジトリ管理を簡単にする](https://zenn.dev/oreo2990/articles/13c80cf34a95af)\n- [pecoを使ったらターミナルの操作が劇的に効率化できた話 - Qiita](https://qiita.com/keisukee/items/9b815e56a173a281f42f)\n\n他には pnpm などの補完がほしいところですが、これは使うコンテナによって必要なものが違うので、Dockerfile の方で有効にしています。例えば pnpm の場合は以下のような感じです。\n\n- [Command line tab-completion | pnpm](https://pnpm.io/completion)\n\n```dockerfile\nUSER vscode\nRUN corepack prepare pnpm@8.2.0 --activate\nRUN pnpm install-completion zsh\n```\n\n## Copilot や VSCode の拡張機能について\n\nこれまではあまり意識せずに Copilot を Codespaces にインストールして使っていたのですが、これを設定している途中で、コンテナ内で開発する際に Copilot が有効にならないことがあることに気づきました。これは Codespaces に限らず、Dev Container でも同じでした。他にもいくつかの拡張機能が動作しないことがあったのですが、これは container.json に設定を追加することで解決しました。\n\n- [GitHub Codespaces での GitHub Copilot の使用 - GitHub Docs](https://docs.github.com/ja/codespaces/codespaces-reference/using-github-copilot-in-github-codespaces)\n- [Development Container Specification](https://containers.dev/implementors/spec/#implementation-specific-steps)\n\n`customizations.vscode.extensions` フィールドを設定することで、コンテナで有効にする VSCode の拡張機能を指定することができるようです。これを使って Copilot や必要な拡張を有効にすることにしました。\n\n```json\n{\n    \"build\": { \"dockerfile\": \"Dockerfile\" },\n    \"customizations\": {\n        \"vscode\": {\n            \"extensions\": [\n                \"github.copilot\",\n                \"astro-build.astro-vscode\" // 例えば Astro を使う場合\n            ]\n        }\n    }\n}\n```\n\n## 今回やらなかったがやりたいこと\n\nCodespaces や Dev Container を使った開発では、シェルの history が残らないため、永続化したい場合は別途手段を用意する必要があるようです。\n\n- [GitHub Codespace で Terminal の入力履歴を永続化し Codepace 間で共有してみる](https://zenn.dev/hankei6km/articles/persist-command-history-in-github-codesapces)\n\nhistory が永続化できるとそもそも不要かもしれませんが、cheat を使ったスニペットを env リポジトリに含めて置けると便利そうです。\n\n- [cheat/cheat: cheat allows you to create and view interactive cheatsheets on the command-line. It was designed to help remind \\*nix system administrators of options for commands that they use frequently, but not frequently enough to remember.](https://github.com/cheat/cheat)\n\n## 2023-05-14 追記\n\nしばらく触っていなかったリポジトリを同じ要領で触ってみたら、DevContainer 側で VSCode の Extention のインストールが全く進まずに困っていたのですが、Dockerfile が原因でした。\nかなり前に公式を参考に devcontainer.json と Dockerfile を作った際に、その Dockerfile はこんな感じに定義されていて、\n\n```\nARG VARIANT=bullseye\nFROM --platform=linux/amd64 mcr.microsoft.com/vscode/devcontainers/base:0-${VARIANT}\n```\n\n`linux/amd64` を指定していると M2 Mac 上のコンテナに Extention がインストールできなくなるようでした。platform は指定しなければ自動で選択してくれるので、\n\n```\nARG VARIANT=bullseye\nFROM mcr.microsoft.com/vscode/devcontainers/base:0-${VARIANT}\n```\n\nに変更して無事動くようになりました。当時参考にしたドキュメントが見つからなかったんですが、現在のものは platform を指定していないので問題なさそうです。\n\n- https://docs.github.com/ja/codespaces/setting-up-your-project-for-codespaces/adding-a-dev-container-configuration/introduction-to-dev-containers\n\nそもそもトレンドとしては Dockerfile は使わず、devcontainer.json だけで完結するのがよいようにも思います。",
    "createdAt": "2023-05-06T00:00:00.000Z",
    "updatedAt": "2023-05-06T00:00:00.000Z",
    "publishedAt": "2023-05-06T00:00:00.000Z",
    "tags": [],
    "path": "/blog/develop-in-codespaces-and-devcontainer"
  },
  {
    "id": "5",
    "title": "CLI から VSCode の拡張を入れる",
    "content": "`--install-extension` というコマンドがあり、これを使うと CLI から拡張機能をインストールできる。\nプロジェクトに直接関係しないけど devcontainer に入っていてほしい、みたいなものに個人の設定で使うと便利。\n\n```\ncode --install-extension mhutchie.git-graph\ncode --install-extension eamodio.gitlens\n```",
    "createdAt": "2024-06-02T20:13:54.000Z",
    "updatedAt": "2024-06-02T20:13:54.000Z",
    "publishedAt": "2024-06-02T20:13:54.000Z",
    "tags": [],
    "path": "/note/5"
  },
  {
    "id": "1",
    "title": "node 22 の標準 glob を利用する",
    "content": "Node 22 では実験的な機能として `glob` と `globSync` が導入されました。\r\n\r\n- https://nodejs.org/en/blog/announcements/v22-release-announce#glob-and-globsync\r\n\r\nこれまで glob パッケージを利用していた場合、次のように置き換えることが出来ます。\r\n\r\n- https://www.npmjs.com/package/glob\r\n\r\n\r\n```diff\r\n- const glob = require('glob');\r\n+ const { glob, globSync} = require('fs');\r\n\r\n  glob('*', (error, matches) => {});\r\n- const matches = glob.sync('*');\r\n+ const matches = globSync('*');\r\n```",
    "createdAt": "2024-06-02T20:07:55.000Z",
    "updatedAt": "2024-06-02T20:07:55.000Z",
    "publishedAt": "2024-06-02T20:07:55.000Z",
    "tags": [],
    "path": "/note/1"
  },
  {
    "id": "4",
    "title": "Node 組み込みテストランナーと swc で TypeScript をテストする",
    "content": "Node 18 から実験的に導入された組み込みのテストランナーがありますが、これが 21 で対象を glob 指定できるようになりました。\r\n\r\n- https://nodejs.org/en/blog/announcements/v18-release-announce#test-runner-module-experimental\r\n- https://nodejs.org/en/blog/announcements/v21-release-announce#support-for-globs-in-the-nodejs-test-runner\r\n\r\nswc-node と組み合わせると、それなりに使えそうなテストランナーになりそうです。\r\n\r\n- https://github.com/swc-project/swc-node\r\n\r\nこれらを用意した状態で次のコマンドにすると、 TS をトランスパイルしつつ watch モードで動くテストランナーが作れます。\r\n\r\n```sh\r\n$ node --import @swc-node/register/esm-register --watch --test 'src/**/*.test.ts'\r\n```\r\n\r\n> [!NOTE]\r\n> webpack などのバンドラーを使って ESM で記述している場合、Node の ESM と共存できるようにする必要があります。\r\n> 自分は import を `*.js` で行うようにし、 `extentionAlias` で `import xxx from './xxx.js'` を `.ts` としても解決できるようにしました。\r\n> https://webpack.js.org/configuration/resolve/#resolveextensionalias",
    "createdAt": "2024-06-02T20:13:39.000Z",
    "updatedAt": "2024-06-02T20:13:39.000Z",
    "publishedAt": "2024-06-02T20:13:39.000Z",
    "tags": [],
    "path": "/note/4"
  },
  {
    "id": "3",
    "title": "@mozilla/readability を使った HTML からの本文抽出",
    "content": "@mozilla/readability を使うと簡単に本文を抽出することができます。これは Firefox のリーダービューで使われているもののようです。\r\n\r\n- https://github.com/mozilla/readability\r\n- https://support.mozilla.org/ja/kb/firefox-reader-view-clutter-free-web-pages\r\n\r\n今回はこの結果を Claude3 に投げたかったので、DOMPurify を組み合わせて最小限文章がわかりそうな DOM として取り出しています。\r\n\r\n- https://github.com/cure53/DOMPurify\r\n\r\n```ts\r\nimport { Readability } from '@mozilla/readability';\r\nimport { JSDOM } from 'jsdom';\r\nimport createDOMPurify from 'dompurify';\r\n\r\nexport const getReadability = async (url: string) => {\r\n    const content = await fetch(url).then(res => res.text());\r\n    const reader = new Readability(new JSDOM(content, {\r\n        url\r\n    }).window.document);\r\n    const readability = (reader.parse() ?? { content: '' });\r\n    return createDOMPurify(new JSDOM('').window).sanitize(readability.content, {\r\n        ALLOWED_TAGS: [\r\n            'h1', 'h2', 'h3', 'h4', 'h5', 'h6',\r\n            'blockquote', 'code', 'pre',\r\n            'p', 'br', 'hr',\r\n            'a', 'img', 'table', 'thead', 'tbody', 'tr', 'th', 'td',\r\n            'ul', 'ol', 'li',\r\n            'dl', 'dt', 'dd',\r\n        ],\r\n        ALLOWED_ATTR: ['href', 'src', 'title', 'alt'],\r\n    });\r\n}\r\n\r\n```",
    "createdAt": "2024-06-02T20:13:24.000Z",
    "updatedAt": "2024-06-02T20:13:24.000Z",
    "publishedAt": "2024-06-02T20:13:24.000Z",
    "tags": [],
    "path": "/note/3"
  },
  {
    "id": "6",
    "title": ":has() でリストが空のときにセクションごと消す",
    "content": "`:has()` が 2023 年末にすべてのブラウザでサポートされて、現実的に利用できるようになった。\r\n\r\n- [:has() - CSS: カスケーディングスタイルシート | MDN](https://developer.mozilla.org/ja/docs/Web/CSS/:has)\r\n- [朗報！ CSSの:has()疑似クラスがすべてのブラウザにサポートされました、:has()疑似クラスの便利な使い方のまとめ | コリス](https://coliss.com/articles/build-websites/operation/css/css-has-pseudo-class.html)\r\n\r\n「渡したセレクターにマッチする子要素を持つ親要素であるか」を判定できるので、例えばリストが空のときにセクションごと消すことができる。\r\n\r\n```html\r\n<style>\r\nsection:has(ul:empty) {\r\n  display: none;\r\n}\r\n</style>\r\n<section class=\"section\">\r\n  <h1>section1</h1>\r\n  <ul>\r\n    <li>item1</li>\r\n    <li>item2</li>\r\n  </ul>\r\n</section>\r\n<section class=\"section\">\r\n  <h1>section2</h1>\r\n  <ul>\r\n  </ul>\r\n</section>\r\n```",
    "createdAt": "2024-06-02T20:14:07.000Z",
    "updatedAt": "2024-06-02T20:14:07.000Z",
    "publishedAt": "2024-06-02T20:14:07.000Z",
    "tags": [],
    "path": "/note/6"
  },
  {
    "id": "2",
    "title": "React 19 Actions",
    "content": "React 19 では、データ更新とそれに伴う一連の流れをうまく扱う方法として Actions が導入されるようです。\r\n例えば、これまでフォームの送信中の状態を次のように扱うことがありましたが、これが React の機能として標準化されます。\r\n\r\n```tsx\r\nconst [isPending, setIsPending] = useState(false);\r\nconst submit = () => {\r\n  setIsPending(true);\r\n  await foo();\r\n  setIsPending(false);\r\n}\r\nreturn (\r\n      <form>\r\n        <button click={submit} disable={isPending}>foo</button>\r\n      </form>\r\n    )\r\n```\r\n\r\n新しく導入される Actions の一つである `useActionState` を利用して書くと次のように書けます。\r\n\r\n```tsx\r\nconst [error, submitAction, isPending] = useActionState(\r\n  async () => {\r\n    const error = await foo();\r\n    if (error) { return error; }\r\n    return null;\r\n  }\r\n)\r\nreturn (\r\n      <form action={submitAction}>\r\n        <button type=\"submit\" disable={isPending}>foo</button>\r\n      </form>\r\n    )\r\n```\r\n\r\nHook に渡した関数は実質的に `submitAction` の内容になっていて、`isPending` はその関数の実行状態に合わせて値が変化します。\r\nこれによって最初のコードと同等に `isPending` を使って UI の状態を変更できる、ということのようです。\r\n\r\n### useFormStatus\r\n\r\nこれに組み合わせて使えるものとして `useFormStatus` という親の `form` の実行状態を取得することが出来る Hook もあります、これは react-dom から提供されるものです。\r\n例えばボタンコンポーネントを作るときにその状態を外から Props として渡すことがあると思いますが、 Actions を使った form の中ではこれを簡略化することが出来ます。\r\n\r\n```tsx\r\nfunction FooSubmit() {\r\n  const { pending } = useFormStatus();\r\n  <button type=\"submit\" disable={pending}>foo</button>\r\n}\r\n\r\nfunction FooForm() {\r\n  const [error, submitAction, isPending] = useActionState(\r\n    async () => {\r\n      const error = await foo();\r\n      if (error) { return error; }\r\n      return null;\r\n    }\r\n  )\r\n  return (\r\n        <form action={submitAction}>\r\n          <FooSubmit />\r\n        </form>\r\n      )\r\n}\r\n```\r\n\r\nこれが `useActionState` の例と同じ動作になるようです。\r\n\r\n### useOptimistic\r\n\r\nActions が失敗したときに巻き戻される `useState` のようなものです。次にコードで `await foo()` が失敗すると、 `value` が `currentValue` に戻ります。\r\n\r\n```tsx\r\nconst [value, setValue] = useOptimistic('currentValue')\r\nconst [error, submitAction, isPending] = useActionState(\r\n  async () => {\r\n    setValue('newValue')\r\n    const error = await foo();\r\n    if (error) { return error; }\r\n    return null;\r\n  }\r\n)>\r\n```\r\n\r\nユーザー名を変更したいが、重複チェックに時間がかかるような場合に、結果の予定を先に UI に反映しておくような場合にその実装が標準化できるようです。\r\n\r\n- https://react.dev/blog/2024/04/25/react-19\r\n- https://react.dev/reference/react-dom/hooks/useFormStatus",
    "createdAt": "2024-06-02T20:13:05.000Z",
    "updatedAt": "2024-06-02T20:13:05.000Z",
    "publishedAt": "2024-06-02T20:13:05.000Z",
    "tags": [],
    "path": "/note/2"
  }
];